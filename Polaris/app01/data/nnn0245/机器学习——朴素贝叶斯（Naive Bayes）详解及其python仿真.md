
--- 
title:  机器学习——朴素贝叶斯（Naive Bayes）详解及其python仿真 
tags: []
categories: [] 

---
一、朴素贝叶斯(naive Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯法实现简单，学习与预测的效率都很高，是一种常用的方法。

那么在掌握朴素贝叶斯算法之前，我们必须了解条件概率和全概率。

1.1、条件概率公式如下：



1.2、全概率公式如下：

指若事件{A1，A2，…，An}构成一个完备事件组且都有正概率，则对任意一个事件B都有：

<img alt="" src="https://img-blog.csdnimg.cn/img_convert/f10e65ced63e2b4cae18608e2749377b.png">

则有



二、贝叶斯定理：

一种有效计算条件概率的方法称为 **贝叶斯定理** 。贝叶斯定理告诉我们如何 **交换条件概率中的条件与结果** ，即如果已知  `P(X|Y)` ，要求  `P(Y|X)` :



这里的每个概率都有其特定的名称：

P ( Y ) ：先验概率。先验概率（prior probability）是指事情还没有发生，求这件事情发生的可能性的大小，是先验概率。它往往作为"由因求果"问题中的"因"出现。

P ( Y ∣ X ) ：后验概率。后验概率是指事情已经发生，求这件事情发生的原因是由某个因素引起的可能性的大小。后验概率的计算要以先验概率为基础

P ( X ∣ Y ) ：条件概率，又叫似然概率，一般是通过历史数据统计得到。一般不把它叫做先验概率，但从定义上也符合先验定义。

三、贝叶斯推论：

结合条件概率可推导出如下公式：

<img alt="" src="https://img-blog.csdnimg.cn/img_convert/7c45fe920a2f276dbe1f52f4ee6adfab.png">

即为贝叶斯公式。把P(Ai)称为先验概率(Prior probability)，即在B事件发生之前，我们对A事件概率的一个判断。

P(Ai|B)称为后验概率(Posterior probability)࿰
