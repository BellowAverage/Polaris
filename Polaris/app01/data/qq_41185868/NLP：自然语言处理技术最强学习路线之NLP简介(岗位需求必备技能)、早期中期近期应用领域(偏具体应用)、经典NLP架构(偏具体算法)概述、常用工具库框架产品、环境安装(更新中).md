
--- 
title:  NLP：自然语言处理技术最强学习路线之NLP简介(岗位需求/必备技能)、早期/中期/近期应用领域(偏具体应用)、经典NLP架构(偏具体算法)概述、常用工具/库/框架/产品、环境安装(更新中) 
tags: []
categories: [] 

---
NLP：自然语言处理技术最强学习路线之NLP简介(岗位需求/必备技能)、早期/中期/近期应用领域(偏具体应用)、经典NLP架构(偏具体算法)概述、常用工具/库/框架/产品、环境安装(更新中)



>  
 **导读**：本文章主要总结了自然语言处理技术在不同时期的代表性算法和技术，以及对应的经典案例应用，当然，也包括近期的LLMs大模型算法的理论算法讲解与部署实战案例。本文章将会永久持续更新，及时追踪和更新NLP领域的SOTA技术…… 






**目录**









































































































































































































































































































































































































































































































## **<strong><strong>NLP**</strong>**<strong>自然语言处理技术**</strong>**<strong>最强学习路线**</strong></strong>

### **1、****NLP市场岗位要求**

#### **<strong><strong>Interview之NLP：人工智能领域求职岗位—自然语言处理NLP算法工程师职位的简介、薪资介绍、知识结构之详细攻略**</strong></strong>









### **2、****NLP应用领域**

#### **<strong><strong>AI：人工智能领域具体应用场景案例介绍之以领域划分(CV领域/DS领域/NLP领域/金融领域/爬虫领域)、以项目划分(AI推荐/AI推断/AI法律咨询/AI挖掘)目录来理解技术交互流程**</strong></strong>







#### **<strong><strong>AI：人工智能领域之国内外人工智能产业应用图谱应用层/基础层详解—AI八大应用领域之医疗/家居/驾驶/零售/城市/教育/金融/交通、(AI三大基础(算法【计算机视觉/自然语言处理/机器学习、科研院所/开源社区】、数据【IOT/互联网/手机/传感器/音视频】、计算【计算芯片/服务器及存储器/AI软件框架/云服务】)**</strong></strong>







### **3、****NLP基本必备技能**

#### **<strong><strong>3.1、**</strong>**<strong>NLP领域英语缩写词、术语等概念简介**</strong></strong>
<td style="vertical-align:top;width:38.8pt;"> **<strong>基本概念**</strong> </td><td style="vertical-align:top;width:387.3pt;"> **<strong>SOTA**</strong>：state-of-the-art，目前最好、最先进、最优的模型；  </td>

**<strong>SOTA**</strong>：state-of-the-art，目前最好、最先进、最优的模型；
<td rowspan="2" style="vertical-align:top;width:38.8pt;"> **<strong>专业概念**</strong> </td><td style="vertical-align:top;width:387.3pt;"> **<strong>token(符号)**</strong>：包括单词和标点。给定句子，如何用一串数字来表示它； **<strong>Sentence Order Prediction**</strong>，SOP语序预测任务； **<strong>Next Sentence Prediction**</strong>，NSP判断两句话是否有顺序关系； </td>

**<strong>token(符号)**</strong>：包括单词和标点。给定句子，如何用一串数字来表示它；

**<strong>Next Sentence Prediction**</strong>，NSP判断两句话是否有顺序关系；
<td style="vertical-align:top;width:387.3pt;"> **<strong>CBOW**</strong>：Continuous Bag-Of-Words Model； **<strong>PTMs**</strong>：Pre-trained Models，预训练模型； </td>

**<strong>PTMs**</strong>：Pre-trained Models，预训练模型；





#### **<strong><strong>3.2、**</strong>**<strong>要掌握**</strong>**<strong>正则表达式在NLP中的基本应用**</strong></strong>

#### **<strong><strong>Computer：正则表达式技术的简介(元字符/普通字符使用字典及其方法总结大全)、相关库介绍、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP：利用python编程语言的split函数结合if判断(T1自定义函数或T2封装函数)实现提取两人对话内容(***分隔txt文档)，并各自保存为txt文档**</strong></strong>







### **4、****NLP公开课****笔记**

#### Paper之ACL&amp;EMNLP：2009年~2019年ACL计算语言学协会年会&amp;EMNLP自然语言处理的经验方法会议历年最佳论文简介及其解读





#### NLP：《NLP Year in Review 2019&amp;NLP_2019_Highlights》2019年自然语言处理领域重要进展回顾及其解读







#### **<strong>AI公开课之NLP：19.03.06何晓冬博士《自然语言与多模态交互前沿技术》课堂笔记以及个人感悟**</strong>







#### **<strong><strong>AI公开课：19.04.03周明—MSRA副院长《NLP的进步如何改变搜索的体验》课堂笔记以及个人感悟**</strong></strong>





#### **<strong><strong>AI公开课之NLP：19.04.04李航—字节跳动AILab总监《深度学习与自然语言处理：评析与展望》课堂笔记以及个人感悟**</strong></strong>







#### **<strong><strong>AI之NLP：2020年6月22日北京智源大会演讲分享之《语音与自然语言处理》之基于深度上下文词表征的语言结构的发现、基于显式上下文表征的语言处理、多语言及多模态任务中的预训练模型、可微分的加权有限状态机及其机器学习应用、启动“智源-京东”任务导向多模态对话大赛、AI新疆域：多模态自然语言处理**</strong></strong>





#### **<strong><strong>AI之NLP：2020年6月21日北京智源大会演讲分享之15:15-15:40黄萱菁教授《自然语言处理中的表示学习》**</strong></strong>





#### **<strong><strong>AI开发者大会之语音语义技术实践与应用：2020年7月3日《NLP在教育行业的应用》、《AI防疫-语音语义技术在政务联络场景中的应用》、《智能客服机器人在售前导购场景中的应用实践》**</strong></strong>







### **5****、NLP领域大语言模型LLMs**

#### **<strong><strong>☆☆☆☆☆**</strong></strong>**综述**

#### **<strong><strong>LLMs：大力出奇迹？Bigger is better？AI下一代浪潮？预训练大语言模型的简介(起源/目的/概述/技术基础/核心/影响/优缺点/未来趋势)、发展史、模型分类及其对比、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP之LLMs：《Zeno Chatbot Report》的翻译与解读—CMU副教授详测七款个类ChatGPT大模型(GPT-2、LLaMa、Alpaca、Vicuna、MPT-Chat、Cohere Command和ChatGPT)**</strong></strong>



#### AI：大模型领域最新算法SOTA总结、人工智能领域AI工具产品集合分门别类(文本类、图片类、编程类、办公类、视频类、音频类、多模态类)的简介、使用方法(持续更新)之详细攻略





#### PTM：预训练大模型时代的多角度思考与辩论—大模型爆发原因、应用思考、数学思考(基于Transformer类的大模型本质上是否基于概率统计)、智能思考(GPT-4比人牛逼甚至要超越人的原因剖析/涌现能力/思维连)、LLMs当前缺点(灾难性遗忘等)之详细攻略





#### **<strong><strong>☆☆☆☆☆**</strong></strong>核心技术总结



#### AGI：人工智能大模型领域实战篇—设计一个类似GPT-3.5/GPT-4的大模型从开发→部署→应用需要经过的八大步骤、为什么只有少数公司和机构能够承担这样的训练成本之详细介绍





#### LLMs：预训练大模型实现全流程详解(以LLaMA为例)—收集数据→数据预处理→模型训练与评估→模型微调与推理→模型部署→实现复杂任务之详细攻略





#### NLP之LLMs：大型语言模型领域LLMs技术发展史、LLMs最新模型的简介、各种维度对比(模型参数/训练时间/训练成本)、在线测试网站集合之详细攻略(持续更新)





#### PTMs：大模型领域之SOTA(最先进模型)的相关术语知识总结(持续积累)、每个LLM开发者都应知道的数字、SOTA算法(NLP领域+CV领域)核心技术重点梳理之详细攻略





#### LLMs：自然语言处理领域—大语言模型的涉及四大技术领域(TL/USL/PT+Fine/Seq2Seq)、十大核心组件之详细攻略





####  LLMs之ChatGPT：研究探讨国内外各大AI机构在预训练大模型领域构建或复现类似ChatGPT失败原因以及ChatGPT适用和不适用任务场景的综合梳理





####  LLMs：构建用于生产的LLM应用程序的挑战与案例经验总结——prompt工程面临的挑战(自然语言的模糊性/成本和延迟/提示VS微调VS替代方案/向前和向后兼容性)、任务组合性(多个任务组成的应用/ 代理-工具-控制流)、有前景的应用案例(AI助手、聊天机器人、编程与游戏、提速学习、交互数据【不适合大量数据分析】、搜索和推荐、销售)之详细攻略







#### LLMs之ChatGPT：研究探讨国内外各大AI机构在预训练大模型领域构建或复现类似ChatGPT失败原因以及ChatGPT适用和不适用任务场景的综合梳理





#### **<strong><strong>LLMs：LLM在**</strong></strong>生产环境中**<strong><strong>实际应用中面临的两大挑战(内存需求+对更长上下文输入需求)+提升LLM部署效率的三大技术(低精度量化+更高效的自注意力算法Flash Attention+优化模型结构【位置嵌入/键-值缓存】)**</strong></strong>





#### **<strong><strong>☆☆☆☆☆LLMs领域代表性算法**</strong></strong>

#### PTMs：预训练大模型算法衍生发展图及其参数对比、基于Transformer的三类基础架构及其代表性算法(BERT/RoBERTa/ALBERT、GPT/LLaMA系列、XLNet/BART/T5)之详细攻略





#### 2023年10月27日，LLMs之ChatGLM3：ChatGLM3/ChatGLM3-6B的简介(多阶段增强+多模态理解+AgentTuning技术)、安装、使用方法之详细攻略







#### 2023年9月25日，LLM之Colossal-LLaMA-2：Colossal-LLaMA-2的简介、安装、使用方法之详细攻略





#### 2023年9月7日，LLMs之FLM-101B：《FLM-101B: An Open LLM and How to Train It with $100K Budget一个开放的LLM和如何用10万美元的预算训练训它》翻译与解读





#### 2023年9月20日，LLMs之InternLM：InternLM-20B的简介、安装、使用方法之详细攻略





#### 2023年9月7日，LLMs之Falcon 180B：Falcon 180B的简介、安装、使用方法之详细攻略





#### 2023年9月6日，LLMs之Baichuan 2：Baichuan 2的简介、安装、使用方法之详细攻略







#### 2023年08月25日，LLMs之Code：Code Llama的简介、安装、使用方法之详细攻略





#### 2023年07月31日，LLMs：Chinese-LLaMA-Alpaca-2的简介、安装、案例实战应用之详细攻略









####  2023年07月18日，LLMs之LLaMA2：LLaMA2的简介(技术细节)、安装、使用方法(开源-免费用于研究和商业用途)之详细攻略





#### 2023年07月11日，LLMs之Baichuan：Baichuan-13B模型的简介(包括Baichuan-7B)、安装、使用方法之详细攻略





#### 2023年07月06日，LLMs之InternLM：InternLM/InternLM-7B模型的简介、安装、使用方法之详细攻略







####  2023年06月25日，LLMs之ChatGLM2：ChatGLM2-6B的简介、安装、使用方法之详细攻略





#### 2023年06月20日，LLMs：《vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention》翻译与解读





#### 2023年06月5日，LLMs：《Orca: Progressive Learning from Complex Explanation Traces of GPT-4》翻译与解读





#### 2023年4月17日，Chinese LLaMA and Alpaca，LLMs：《Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca》翻译与解读



  

#### 2023年3月30日，LLMs之Vicuna：《Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality》翻译与解读







#### 2023年03月29日，AIGC：ColossalChat(基于LLM和RLHF技术的类似ChatGPT的聊天机器人)/ColossalAI的简介、安装、使用方法之详细攻略

  



#### 2023年3月15日，AIGC之GPT-4：GPT-4的简介(核心原理/意义/亮点/技术点/缺点/使用建议)、使用方法、案例应用(计算能力/代码能力/看图能力等)之详细攻略





##### LLMs之GPT-4：基于OpenAl新增函数调用功能的简介、两种方法(原生SDK和LangChain框架)实现之详细攻略







#### 2023年3月14日，LLMs之Alpaca：《Alpaca: A Strong, Replicable Instruction-Following Model》翻译与解读







#### 2023年03月10日，LLMs之GLM-130B/ChatGLM：《GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL》翻译与解读



  



#### 2023年2月25日，AIGC之LLaMA：《LLaMA: Open and Efficient Foundation Language Models》翻译与解读





#### 2022年11月30日，AIGC：ChatGPT(一个里程碑式的对话聊天机器人)的简介(意义/功能/核心技术等)、使用方法(七类任务)、案例应用(提问基础性/事实性/逻辑性/创造性/开放性的问题以及编程相关)之详细攻略







#### LLMs——2022年1月~2022年12月

下边四篇论文分别从微调、模型结构、多语言模型以及模型规模等角度，探索了提高语言模型性能和泛化能力的不同方法。它们以开源的形式发布强大的语言模型，为NLP研究和应用提供了有力工具。

#### LLMs之InstructGPT：《Training language models to follow instructions with human feedback》翻译与解读





#### LLMs：《PaLM: Scaling Language Modeling with Pathways》翻译与解读





#### LLMs:《OPT: Open Pre-trained Transformer Language Models》翻译与解读





#### LLMs：《BLOOM: A 176B-Parameter Open-Access Multilingual Language Model》翻译与解读







### **6、多模态技术(NLP+CV)**

#### **<strong><strong>AI：人工智能的多模态融合模型的简介、发展以及未来趋势**</strong></strong>





### **7、****NLP相关竞赛**

#### **<strong><strong>Competition之ML/DL：机器学习、深度学习各种计算机视觉、自然语言处理、科学预测等等比赛竞赛简介**</strong></strong>







### **8、****NLP算法工程师基本技能**

#### **<strong><strong>一、自然语言处理技术的简介**</strong></strong>

#### **<strong><strong>二、自然语言处理技术相关概念简介**</strong></strong>

#### **<strong><strong>四**</strong>**<strong>、NLP具体应用领域(偏具体应用)及其应用案例**</strong></strong>

#### **<strong><strong>五、经典NLP算法(偏具体算法)简介及其应用案例**</strong></strong>

#### **<strong><strong>六、NLP领域常用工具、库/框架、现有产品**</strong></strong>

#### **<strong><strong>七、NLP环境安装**</strong></strong>

#### **<strong><strong>八、NLP领域常用数据集**</strong></strong>

#### **<strong><strong>九、NLP编程代码技巧**</strong></strong>



## **<strong><strong>☆☆一、自然语言处理技术的简介**</strong></strong>

#### **<strong><strong>NLP：自然语言处理技术的简介(是什么/做什么/怎么做)、领域方向-细分任务及其评估标准、发展历史、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP：自然语言处理技术之NLP技术实践—自然语言/人类语言“计算机化”的简介、常用方法分类(基于规则/基于统计，离散式/分布式)之详细攻略**</strong></strong>





#### **<strong><strong>NLP：自然语言处理领域常见的文本特征表示/文本特征抽取(本质都是“数字化”)的简介、四大类方法(基于规则/基于统计，离散式【one-hot、BOW、TF-IDF】/分布式)之详细攻略**</strong></strong>





#### **<strong><strong>NLP：LM语言模型的简介(词嵌入模型VS语言模型VS预训练模型)、发展历史(N-Gram→RNN→Transformer)、案例应用(语音识别/机器翻译/自然语言生成)之详细攻略**</strong></strong>





#### NLP：自然语言处理领域技术的发展史—多种维度分类—四个阶段/四大思想/四大范式/四大方法论(规则→统计→深度学习→大模型)之详细攻略





#### NLP：自然语言处理领域技术的发展史—有监督模型没落、无监督模型兴起(两代PTM+词向量发展史+预训练语言模型/自监督学习)、神经网络算法对比(BP/W2C/PTM)的兴起之详细攻略





#### NLP：自然语言处理领域的PTM发展史(无监督模型兴起)—LLMs技术迭代两大阶段(第一代PTMs(词向量，NNLM→Word2Vec→ELMO】、第二代PTMs(语言模型，Attention→Transformer→GPT/BERT系列】)对比、关系梳理、代表性算法对比(持续更新)





#### **<strong><strong>NLP：自然语言处理领域技术的发展史—PTM预训练大模型(LLMs+多模态)的简介(2017~2022年大模型领域各个算法的诞生时间/参数量/机构/功能/特点，图表形式)之详细攻略**</strong></strong>





#### **<strong><strong>LLMs：大力出奇迹？Bigger is better？AI下一代浪潮？预训练大语言模型的简介(起源/目的/概述/技术基础/核心/影响/优缺点/未来趋势)、发展史、模型分类及其对比、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>LLMs：自然语言处理领域—大语言模型的**</strong>**<strong>涉及四大技术领域(TL/USL/PT+Fine/Seq2Seq)、十大核心组件之详细攻略**</strong></strong>





#### **<strong><strong>NLP之PTM：自然语言处理领域—预训练大模型时代各种吊炸天算法概述(NNLM→Word2Vec→ELMO→Attention→Transformer→GPT/BERT系列)、关系梳理、模型对比之详细**</strong></strong>





#### **<strong><strong>NLP之LLMs：基于Transformer的三类基础架构及其代表性算法(BERT/RoBERTa/ALBERT/T5、GPT系列、XLNet/T-NLG)之详细攻略**</strong></strong>





#### **<strong><strong>Paper：大模型之《Pre-Trained Models: Past, Present and Future大规模预训练模型的发展历史、最新现状和未来发展三个方向》翻译与解读**</strong></strong>





#### **<strong><strong>Paper之ACL&amp;EMNLP：2009年~2019年ACL计算语言学协会年会&amp;EMNLP自然语言处理的经验方法会议历年最佳论文简介及其解读**</strong></strong>





#### **<strong><strong>NLP：《NLP Year in Review 2019&amp;NLP_2019_Highlights》2019年自然语言处理领域重要进展回顾及其解读**</strong></strong>





#### **<strong><strong>NLP：LSTM之父眼中的深度学习十年简史《The 2010s: Our Decade of Deep Learning / Outlook on the 2020s》的参考文献**</strong></strong>







## **<strong><strong>☆☆二、自然语言处理技术相关概念简介**</strong></strong>

### **<strong><strong>2.1、基础概念**</strong></strong>

#### **NLP：自然语言处理技术之词语级别相关术语解释(如上位词/WordNet)、基于词汇层面的词法分析六大任务(分词/词性标注/词干提取-词形还原/新词发现/形态分析/拼写校正)的简介及其应用**





#### **NLP之NLTK：利用nltk对文本数据语料库实现数据预处理(断句+分词+去除停用词+词性标注+文本标准化【词干提取+词形还原】)案例应用**





#### **NLP之NLTK：利用nltk对文本数据语料库实现将句子中的词组分为不同的语义单元三种方法(Chunk组块分析/NER命名实体识别/短语结构分析)的应用案例**





#### **NLP之NLTK：利用NLTK的WordNet模块来查询某单词的同义词集合并获取其定义/例句/上位词进而深入理解单词的含义和关联性应用案例**





### **<strong><strong>2.2、进阶概念**</strong></strong>

更新中……









## **<strong><strong>☆☆四、NLP具体应用领域(偏具体应用)及其应用案例**</strong></strong>

<img alt="" height="644" src="https://img-blog.csdnimg.cn/eff2a23a00ae465a9df80c2dc668c792.png" width="566">





### **4.1、基本****技术**

### **4.1.1、****数据集处理**

#### **<strong><strong>NLP之TFTS读入数据：TF之TFTS读入时间序列数据的几种方法**</strong></strong>





### ** 4.1.2、文本特征表示**

#### **<strong><strong>NLP：自然语言处理技术中文本特征表示/文本特征抽取(本质均“数字化”)的简介、四大类方法(基于规则/概统/离散式【one-hot、BOW、TF-IDF】/分布式【词向量CO-SVD→NNLM→Word2Vec→GloVe→FastText+预训练语言模型Transformner→GPT/BERT】)之详细攻略**</strong></strong>





#### **<strong><strong>NLP之nltk：基于nltk库实现句子分词及标注对应词性、句子分割、波特词干算法进行词干提取代码案例实现**</strong></strong>









### ** 4.1.3、****文本预处理**

#### NLP：对文本进行预处理操作(分词+合并+去掉标点符号和空格+去重+词性标注并转为字典、特征编码并存为字典、标签编码并存为字典)实现实际样本特征编码、实际样本标签编码应用案例









### **4.1.4、****正则表达式相关**

#### **<strong><strong>NLP：利用re模块对字符串数据实现多个关键词模糊匹配，模糊匹配测试数据并统计个数输出字典**</strong></strong>





#### **<strong><strong>NLP：利用re和collections模块进行词频统计之关键词匹配并统计个数以字典形式输出，利用正则表达式findall、split、match函数对字符串组成的列表数据，进行关键词定位匹配并统计输**</strong></strong>





#### **<strong><strong>NLP：对字符串按照一个、多个自定义分隔符进行分割、将列表转为字符串同时自定义连接符**</strong></strong>





#### **<strong><strong>NLP：以周杰伦的《Mojito》歌词为例字符串切分之清除一段由列表组成的字符串文本中的所有杂乱符号**</strong></strong>







### **4.1.5、****词向量/词云图**

#### **<strong><strong>NLP之WordCloud：基于jieba+matplotlib库对一段文本生成词云图~~情人节最好的礼物(给你一张过去的词云图，看看那时我们的爱情)**</strong></strong>





#### **<strong><strong>NLP之gensim：基于fetch_20newsgroups数据集利用word2vec算法进行词向量训练并推理(输出指定单词最相关的10个词汇)**</strong></strong>





#### **<strong><strong>NLP之word2vec：利用 Wikipedia Text(中文维基百科)语料+Word2vec工具来训练简体中文词向量**</strong></strong>





#### **<strong><strong>NLP之TF之LSTM：基于Tensorflow框架采用PTB数据集建立LSTM网络的自然语言建模**</strong></strong>



  

### **4.2、进阶技术——常见场景应用**

### **NLP：自然语言处理常用任务简介、GLUE基准(通用语言理解评估，四类九个)和SuperGLUE基准的简介、任务分类、使用方法之详细攻略**





### NLP：自然语言技术领域相关任务分类—七大任务(表示→提取→匹配→分类→聚类→生成→问答)、两大层次(五种顶层+四种底层)、LLMs四大类(无监督预训练/有监督微调/RL微调/多模态增强)之详细攻略



### 4.2.0、词法分析/句子分析/语义分析/信息抽取

#### NLP：自然语言技术领域相关任务分类—七大任务(表示→提取→匹配→分类→聚类→生成→问答)、两大层次(五种顶层+四种底层)、LLMs四大类(无监督预训练/有监督微调/RL微调/多模态增强)之详细攻略





#### NLP：利用预训练语言模型实现四种底层基本任务—词法分析(分词/词频统计/词性标注/词向量)、句子分析(依存句法分析)、语义分析(相似度计算)、信息抽取(命名实体识别NER/提取短语/提取句子)应用案例实现代码





#### NLP：利用预训练语言模型实现四种底层基本任务—词法分析(词向量)、语义分析(语义解析)、信息抽取(命名实体识别NER)应用案例







### **4.2.1、****关键词提取/摘要提取**

#### **<strong><strong>NLP：基于textrank4zh库对文本实现提取文本关键词、文本关键短语和文本摘要**</strong></strong>





#### **<strong><strong>NLP：基于snownlp库对文本实现提取文本关键词和文本摘要**</strong></strong>





#### **<strong><strong>NLP：基于nltk和jieba库对文本实现提取文本摘要(两种方法实现：top_n_summary和mean_scored_summary)**</strong></strong>







### **4.2.2、****主题模型TM**

#### **<strong><strong>NLP之TM：基于gensim库调用20newsgr学习doc-topic分布并保存为train-svm-lda.txt、test-svm-lda.txt**</strong></strong>





#### **<strong><strong>NLP之TM之Dirichlet：朴素贝叶斯NB的先验概率之Dirichlet分布的应用**</strong></strong>





#### **<strong><strong>NLP之TM之LDA：利用LDA算法瞬时掌握文档的主题内容—利用希拉里邮件数据集训练LDA模型并对新文本进行主题分类**</strong></strong>





#### NLP之TM：基于多个文本数据(jieba分词+Dictionary构建字典+BoW转词频向量)利用LDA模型(gensim)实现主题模型进而转为结构化数据应用案例





#### NLP之TM：基于多个文本数据(CountVectorizer转词频向量)利用LDA模型(sklearn)实现主题模型进而转为结构化数据应用案例





#### NLP之TM：基于多个文本数据(TfidfVectorizer向量化)利用NMF模型(sklearn)实现主题模型进而转为结构化数据应用案例





#### NLP之TM：基于多个文本数据(BertTokenizer)利用BERT预训练模型(transformers)结合K-means均值聚类算法对文本向量进行聚类实现主题模型进而转为结构化数据应用案例







### **4.2.3、<strong><strong>文档结构化**</strong></strong>

#### **<strong><strong>NLP：文档结构化(将大量的自然语言文本数据转化为结构化数据)的简介(LDA对比NMF等)、常用四大方法(依存分析/命名实体识别/主题模型/结构化序列标记)、案例应用之详细攻略**</strong></strong>









### **4.2.4、文本**相似度计算

#### NLP之TextSimil：基于两份文档数据分别利用基于统计的词袋模型(词频/TF-IDF)、词嵌入模型(Word2Vec/GloVe)、神经网络(CNN/RNN学习文档表示)、预训练模型(BERT文档的嵌入表示)结合实现文本相似度计算











### **4.2.5、****文本分类**

#### **<strong><strong>(1)、语种检测**</strong>**<strong>分类**</strong></strong>

#### **<strong><strong>NLP之NB：基于sklearn库利用不同语种数据集训练NB(朴素贝叶斯)算法，对新语种进行语种检测**</strong></strong>









#### **<strong><strong>(2)、文本情感分类/**</strong>**<strong>文本情感分析TEA**</strong></strong>

#### **<strong><strong>NLP之TEA之CNN：利用CNN算法实现对句子分类+进行情感分析(预测句子情感)**</strong></strong>







#### **<strong><strong>NLP之TEA：自然语言处理之文本情感分析的简介、算法、应用、实现流程方法、案例应用之详细攻略**</strong></strong>







#### **<strong><strong>NLP之TEA：基于python编程(jieba库)实现中文文本情感分析(得到的是情感评分)之全部代码**</strong></strong>









#### **<strong><strong>NLP之TEA：基于SnowNLP实现自然语言处理之对输入文本进行情感分析(分词→词性标注→拼音&amp;简繁转换→情感分析→测试)**</strong></strong>







#### **<strong><strong>NLP之TEA之NB/LoR：基于NB和LoR算法对Kaggle IMDB影评数据集(国外类似豆瓣电影)情感分析进行分类**</strong></strong>







#### **<strong><strong>NLP之TEA之NB/LoR：利用NB(朴素贝叶斯)、LoR(逻辑斯蒂回归)算法(+TfidfVectorizer)对Rotten Tomatoes影评数据集进行文本情感分析—五分类预测**</strong></strong>







#### **<strong><strong>NLP之TEA之NB/LoR：利用NB(朴素贝叶斯)、LoR(逻辑斯蒂回归)算法(+CountVectorizer)对Rotten Tomatoes影评数据集进行文本情感分析—五分类预测**</strong></strong>







#### **<strong><strong>NLP之TEA之NB/GBT：基于朴素贝叶斯(count/tfidf+网格搜索+4fCrva)、梯度提升树(w2c+网格搜索+4fCrva)算法对IMDB影评数据集进行文本情感分析(情感二分类预测)**</strong></strong>



  

### **4.2.6、****机器翻译**



### **4.2.7、****语音识别****ASR**

#### **<strong><strong>NLP之ASR：语音识别技术(Automatic Speech Recognition)的简介、发展历史、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP之ASR：基于pyaudio利用python进行语音生成、语音识别总结及其案例详细攻略**</strong></strong>





#### **<strong><strong>NLP之ASR：基于python和机器学习算法带你玩转的语音实时识别技术**</strong></strong>









### 4.2.8、**文本生成相关(基于传统规则/基于大模型)**

#### NLP：自然语言处理领域——文本生成任务之基于规则预定义填充模板和填充词汇列表通过随机选择词汇填入模板中实现文本生成任务





#### **<strong><strong>LLMs之BERT：基于s框架利用预训练Transformer(如BERT)进行多任务学习(添加自定义任务—文本情感分类)训练并进行模型打包和模型推理应用案例实现代码**</strong></strong>





#### **<strong><strong>LLMs之BERT：基于s框架利用预训练Transformer进行多任务学习(自定义任务—文本情感分类和命名实体识别NER)训练并进行模型打包和模型推理应用案例实现代码**</strong></strong>





#### **LLMS之GPT-2：基于大型语料数据集(分词和编码)并进行数据预处理利用GPT-2模型实现模型训练调优应用案例实现代码**





#### **LLMS之GPT-3：基于大型语料数据集(分词和编码)并进行数据预处理利用GPT-3模型实现模型训练调优应用案例实现代码**





#### LLMs：从头到尾手把手教大家利用ChatGLM-6B模型实现训练、部署、推理(CLI/GUI)、微调(两个提效技巧+三种微调方法)图文教程之详细攻略





#### **<strong><strong>LLMs：在单机CPU+Windows系统上实LLaMA模型(基于facebookresearch的GitHub)进行模型部署且实现模型推理全流程步骤的图文教程(非常详细)**</strong></strong>





#### **<strong><strong>LLMs：在单机CPU+Windows系统上实现中文LLaMA算法(基于Chinese-LLaMA-Alpaca)进行模型部署且实现模型推理全流程步骤的图文教程(非常详细)**</strong></strong>





#### LLMs：基于Chinese-LLaMA-Alpaca开源代码在Ng单卡利用LLaMA(Meta)和Alpaca(斯坦福)实现定义数据集(生成指令数据)→数据预处理(token分词/合并权重)→预训练(LoRA的参数/LLaMA的参数)→指令微调LoRA权重(继续训练/全新训练)→模型推理(CLI、GUI【webui/LLaMACha/LangChain】)





#### LLMs：在Linux服务器系统上实Vicuna-7B本地化部署(基于facebookresearch的GitHub)进行模型部署且实现模型推理全流程步骤的图文教程(非常详细)





### 4.2.9、**文本理解相关(基于大模型)**

#### LLMs：基于Langchain框架利用ChatGLM大模型接入本地知识库实现问答响应项目图文教程之详细攻略





#### LLMs：LLMs场景实战案例应用之基于自然语言交互+SQL查询+Algorithm(构建高效数据库+快速缩小搜索范围→解决高维+高效查找)查找的内部数据搜索和问答应用案例的简介、具体实现之详细攻略





#### LLMs：针对**数据预处理(嵌入向量等)+基于Langchain框架利用ChatGLM、LLaMA、Vicuna等大模型接入本地知识库通过***等算法对对搜索结果进行排名和**并结合知识图谱进行业务智能洞察系统【排序和推荐】







## **<strong><strong>☆☆五、经典NLP算法(偏具体算法)简介及其应用案例**</strong></strong>

### **5.1、****基准****相关**

#### **<strong><strong>NLP：自然语言处理常用任务简介、GLUE基准(通用语言理解评估，四类九个)和SuperGLUE基准的简介、任务分类、使用方法之详细攻略**</strong></strong>







### **5.2、****具体算法**

#### **<strong><strong>NLP之WE之CBOW&amp;Skip-Gram：CBOW&amp;Skip-Gram算法概念相关论文、原理配图、关键步骤之详细攻略**</strong></strong>





#### **<strong><strong>NLP之WE之Skip-Gram：基于TF利用Skip-Gram模型实现词嵌入并进行可视化、过程全记录**</strong></strong>





#### **<strong><strong>NLP：Word Embedding词嵌入/word2vec词向量思想方法(一种主流的分布式表示)的简介、使用方法、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP之ELMo：ELMo模型的简介(解决一词多义的思路)、结构(预训练过程、如何使用ELMo的编码值、推理过程)之详细攻略**</strong></strong>





#### **<strong><strong>DL之Transformer：Transformer的简介(优缺点/架构详解，基于Transformer的系列架构对比分析)、使用方法(NLP领域/CV领域)、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>NLP之GPT-1/GPT-2：GPT-1的概述(简介、原理、意义、结构、创新点、优缺点、数据集)、为何单向Transfo、模型结构、训练过程，GPT-2的概述(大数据、大模型、灵感点)之详细攻略**</strong></strong>





#### **<strong><strong>NLP之BERT：BERT的简介(背景、改进点、创新点、简介、意义、原理、优缺点、总结与评价)、模型结构、训练过程(MLM、NSP任务的概述)之详细攻略**</strong></strong>





#### **<strong><strong>NLP：NLP领域没有最强，只有更强的模型——GPT-3的简介、安装、使用方法之详细攻略**</strong></strong>





#### **<strong><strong>NLP之PLUG：阿里达摩院发布最大中文预训练语言模型PLUG的简介、架构组成、模型训练、使用方法之详细攻略**</strong></strong>









## **<strong><strong>☆☆六、NLP领域常用工具、库/框架、现有产品**</strong></strong>

### **6.1、常用框架和库**

**N-gram工具**：

**RNN工具**：

**SRILM工具**：





#### **<strong><strong>AI之DS/CV/NLP：Python与人工智能相关的库/框架(机器学习&amp;深度学习&amp;数据科学/计算机视觉/自然语言处理)的简介、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>Py之word2vec：word2vec的简介、安装、案例应用之详细攻略**</strong></strong>





#### **<strong><strong>Py之jieba：Python包之jieba包(中文分词最好的组件)简介、安装、使用方法之详细攻略**</strong></strong>





#### **<strong><strong>Py之nltk：nltk包的简介、安装、使用方法、代码实现之详细攻略**</strong></strong>







#### **<strong><strong>Py之gensim：gensim的简介、安装、使用方法之详细攻略**</strong></strong>





#### **<strong><strong>Py之SnowNLP：SnowNLP中文处理包的简介、安装、使用方法、代码实现之详细攻略**</strong></strong>





#### Py之thulac：THULAC的简介、安装、使用方法之详细攻略





#### NLP之ltp：LTP(一款中文自然语言处理工具)的简介、安装、使用方法(分词/词性标注/命名实体识别/依存句法分析/语义角色标注)之详细攻略







#### **<strong><strong>Py之textrank4zh：textrank4zh的简介、安装、使用方法之详细攻略**</strong></strong>





#### Py之spacy：spacy/spacy-transformers 的简介、安装、使用方法之详细攻略





#### Py之transformers：transformers的简介、安装、使用方法、案例应用之详细攻略





#### **<strong><strong>NLP之ModelScope：基于ModelScope框架的afqmc数据集利用StructBERT预训练模型的文本相似度算法实现文本分类任务图文教程之详细攻略**</strong></strong>







### **6.2、主流产品**

更新中……





## **<strong><strong>☆☆七、NLP环境安装**</strong></strong>

### **7.1、环境搭建**

#### **<strong><strong>DL之IDE：深度学习环境安装之计算机视觉开发环境搭建的详细流程(Ubuntu16.04+cuda9.0+cuDNN7.4.2+tensorflow_gpu)**</strong></strong>





#### **<strong><strong>DL之IDE：深度学习环境安装之Visual Studio 2015版本+CUDA8.0+Cudnn8.0+OpenCV 3.1.0版本完美搭配安装图文教程之详细攻略**</strong></strong>





#### **<strong><strong>DL之IDE：深度学习环境安装之Tensorflow/tensorflow_gpu+Cuda+Cudnn(最清楚/最快捷)之详细攻略(图文教程)**</strong></strong>





#### **<strong><strong>DL之IDE：深度学习环境安装之CUDA的简介(显卡GPU/驱动/CUDA间的关系)、安装(根据本地电脑的NVIDIA显卡驱动版本去正确匹配CUDA版本)之详细攻略**</strong></strong>





#### **<strong><strong>DL之IDE：深度学习环境安装之NVIDIA驱动程序安装图文教程(根据Anaconda的CUDA版本去安装对应匹配的NVIDIA)之详细攻略**</strong></strong>





#### **<strong><strong>TensorFlow：深度学习框架TensorFlow/TensorFlow_GPU的简介、安装、测试之详细攻略**</strong></strong>







### **7.2、**LLMs领域**大模型部署实战案例**

#### LLMs：预训练大模型六大步骤实现全流程详解(以LLaMA为例)—收集数据→数据预处理→模型训练与评估→模型微调与推理→模型部署→实现复杂任务之详细攻略





#### **7.2.1、部署**ChatGLM-6B：混合精度+ZeRO+fine-tuning/P-tuning v2/LoRA

##### LLMs：从头到尾手把手教大家利用ChatGLM-6B模型实现训练、部署、推理(CLI/GUI)、微调(两个提效技巧+三种微调方法)图文教程之详细攻略





##### LLMs：基于Langchain框架利用ChatGLM大模型接入本地知识库实现问答响应项目图文教程之详细攻略





#### **7.2.2、部署中文版**LLaMA系列/Alpaca**<strong><strong>系列**</strong>——**<strong>Chinese-LLaMA-Alpaca、Chinese-Alpaca-LoRA-7b**</strong></strong>：合并权重+LoRA技巧+指令微调

##### **<strong><strong>LLMs：在单机CPU+Windows系统上实LLaMA模型(基于facebookresearch的GitHub)进行模型部署且实现模型推理全流程步骤的图文教程(非常详细)**</strong></strong>





##### **<strong><strong>LLMs：在单机CPU+Windows系统上实现中文LLaMA算法(基于Chinese-LLaMA-Alpaca)进行模型部署且实现模型推理全流程步骤的图文教程(非常详细)**</strong></strong>





##### LLMs：基于Chinese-LLaMA-Alpaca开源代码在Ng单卡利用LLaMA(Meta)和Alpaca(斯坦福)实现定义数据集(生成指令数据)→数据预处理(token分词/合并权重)→预训练(LoRA的参数/LLaMA的参数)→指令微调LoRA权重(继续训练/全新训练)→模型推理(CLI、GUI【webui/LLaMACha/LangChain】)







#### **7.2.**3、**部署原始**LLaMA系列/Alpaca**<strong><strong>系列**</strong>——</strong>多卡并行+LoRA技巧、多卡并行+QLoRA技巧

##### LLMs之Alpaca_LoRA：Alpaca_LoRA简介(痛点/改进)、实战案例—基于CentOS和多卡(A800+并行技术)实现全流程完整复现Alpaca_7B—安装依赖、转换为HF模型文件、模型微调(full fine-turning+LoRA+单卡/多卡)、模型推理(CLI/llama.cpp/Docker封装)图文教程之详细攻略





##### LLMs之LLaMA-7B-QLoRA：基于Alpaca-Lora代码在CentOS和多卡(A800+并行技术)实现全流程完整复现LLaMA-7B—安装依赖、转换为HF模型文件、模型微调(QLoRA+单卡/多卡)、模型推理(对比终端命令/llama.cpp/Docker封装)图文教程之详细攻略







#### **7.2.4、部署**Vicuna：权重合并

##### LLMs：在Linux服务器系统上实Vicuna-7B本地化部署(基于facebookresearch的GitHub)进行模型权重合并(llama-7b模型与delta模型权重)、模型部署且实现模型推理全流程步骤的图文教程(非常详细)





#### **7.2.5、部署**ChatGLM2

更新中……





#### **7.2.6、部署LLaMA2**

##### **LLMs之LLaMA2：基于text-generation-webui工具来本地部署并对LLaMA2模型实现推理执行对话聊天问答任务(一键安装tg webui+手动下载模型+启动WebUI服务)、同时微调LLaMA2模型(采用Conda环境安装tg webui+PyTorch→CLI/GUI下载模型→启动WebUI服务→GUI式+LoRA微调→加载推理)之图文教程详细攻略**





##### **LLMs之LLaMA2：基于云端进行一键部署对LLaMA2模型实现推理(基于text-generation-webui)执行对话聊天问答任务、同时微调LLaMA2模型(配置云端环境【A100】→下载数据集【datasets】→加载模型【transformers】→分词→模型训练【peft+SFTTrainer+wandb】→基于HuggingFace实现云端分享)之图文教程详细攻略**





##### **LLMs之LLaMA2：基于LocalGPT利用LLaMA2模型实现本地化的知识库(Chroma)并与本地文档(基于langchain生成嵌入)进行对话问答图文教程+代码详解之详细攻略**





#### 





## **<strong><strong>☆☆八、NLP领域常用数据集**</strong></strong>

#### **<strong><strong>Dataset：数据集集合(NLP方向数据集)——常见的自然语言处理数据集大集合(建议收藏，持续更新)**</strong></strong>







## **<strong><strong>☆☆九、NLP编程代码技巧**</strong></strong>

### 9.1、流水线实现技巧

#### **LLMS之GPT-2：基于大型语料数据集(分词和编码)并进行数据预处理利用GPT-2模型实现模型训练调优应用案例实现代码**





#### **LLMS之GPT-3：基于大型语料数据集(分词和编码)并进行数据预处理利用GPT-3模型实现模型训练调优应用案例实现代码**







### 9.2、工程化/系统优化技巧

#### (1)、分布式高性能优化

##### ML之DistributedML：分布式机器学习系统性能优化的简介(分析系统性能瓶颈)、性能调优常用库(CUDA的GPU加速+NCCL多卡通信+RDMA高性能网络传输+分布式系统性能监控)及其使用方法之详细攻略












