
--- 
title:  精确率、召回率、F1以及推荐系统相关评测指标 
tags: []
categories: [] 

---
## 1、分类指标

### 精确率和召回率多用于二分类问题

|真实结果/预测结果|正（P）|负（N）
|------
|正（P）|TP|FN
|负（N）|FP|TN

精确率（P） =  
      
       
        
         
          
          
            T 
           
          
            P 
           
          
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            P 
           
          
         
        
       
         \frac{TP}{TP + FP} 
        
       
     TP+FPTP​ 表示被分为正例的示例中实际为正例的比例

召回率（R）=  
      
       
        
         
          
          
            T 
           
          
            P 
           
          
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
         
        
       
         \frac{TP}{TP + FN} 
        
       
     TP+FNTP​ 召回率是覆盖面的度量，度量有多个正例被分为正例

理想状态下，精确率和召回率越高越好，但事实是两者是矛盾的： 搜索网页时，只返回最相关的那一个网页，则准确率为100%，而召回率就特别的低。如果返回全部网页，则召回率为100%，但准确率特别的低。

举个栗子假设我们手上有100个正样本，40个负样本，我们要找出所有的正样本，系统查找出80个，其中只有60个是真正的正样本，计算上述各指标。 TP: 将正类预测为正类数 60 FN: 将正类预测为负类数 100-60 = 40 FP: 将负类预测为正类数 80-60 = 20 TN: 将负类预测为负类数 40-20=20 准确率(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 80/140 精确率(precision) = TP/(TP+FP) = 60/80 召回率(recall) = TP/(TP+FN) = 60/100

### F1值是精确率和召回率的调和平均值

 
      
       
        
         
         
           2 
          
          
          
            F 
           
          
            1 
           
          
         
        
          = 
         
         
         
           1 
          
         
           P 
          
         
        
          + 
         
         
         
           1 
          
         
           R 
          
         
        
       
         \frac{2}{F1} = \frac{1}{P} + \frac{1}{R} 
        
       
     F12​=P1​+R1​

### 准确率和错误率也是常用的评估指标

准确率（accuracy） =

 
      
       
        
         
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            T 
           
          
            N 
           
          
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
            + 
           
          
            T 
           
          
            N 
           
          
         
        
       
         \frac{TP+TN}{TP+FP+FN+TN} 
        
       
     TP+FP+FN+TNTP+TN​

错误率（error rate） =  
      
       
        
         
          
          
            F 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
            + 
           
          
            T 
           
          
            N 
           
          
         
        
       
         \frac{FP+FN}{TP+FP+FN+TN} 
        
       
     TP+FP+FN+TNFP+FN​

精确率是一个二分类指标，而准确率则能应用于多分类 准确率（accuracy） =

 
      
       
        
         
         
           1 
          
         
           n 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
        
          I 
         
        
          ( 
         
        
          f 
         
        
          ( 
         
         
         
           x 
          
         
           i 
          
         
        
          ) 
         
        
          = 
         
         
         
           y 
          
         
           i 
          
         
        
          ) 
         
        
       
         \frac{1}{n}\sum_{i=1}I(f(x_i) = y_i) 
        
       
     n1​i=1∑​I(f(xi​)=yi​)

### ROC 和AUC

使用精确率和召回率进行模型评估时，需要多预测概率设分类阈值，使得模型多了一个超参数，并且这个超参数会影响模型的泛化能力。 ROC曲线不需要设定这样的阈值，ROC的纵坐标是真正率，横坐标是假正率，其对应的计算公式如下：

真正率

 
      
       
        
        
          T 
         
        
          P 
         
        
          R 
         
        
          = 
         
         
          
          
            T 
           
          
            P 
           
          
          
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
         
        
       
         TPR = \frac{TP}{TP+FN} 
        
       
     TPR=TP+FNTP​ 假正率

 
      
       
        
        
          F 
         
        
          P 
         
        
          R 
         
        
          = 
         
         
          
          
            F 
           
          
            P 
           
          
          
          
            F 
           
          
            P 
           
          
            + 
           
          
            T 
           
          
            N 
           
          
         
        
       
         FPR = \frac{FP}{FP+TN} 
        
       
     FPR=FP+TNFP​

绘制ROC曲线的方法：首先对所有样本按预测概率进行排序，以每条样本的预测概率为阈值，计算对应的FPR和TPR，然后用线段连接。

AUC 即ROC曲线下的面积，取值越大说明模型越可能将正样本排在负样本的前面。AUC等于随机挑选一个正样本和负样本时，分类器将正样本排前面的概率 AUC考虑的是样本的排序质量，他与排序误差有密切的关系

### 对数损失

是对预测概率的似然估计  
      
       
        
        
          l 
         
        
          o 
         
        
          g 
         
        
          l 
         
        
          o 
         
        
          s 
         
        
          s 
         
        
          = 
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          P 
         
        
          ( 
         
        
          Y 
         
        
          ∣ 
         
        
          X 
         
        
          ) 
         
        
       
         log loss = -logP(Y|X) 
        
       
     logloss=−logP(Y∣X) 对数损失的本质是利用样本中的已知分布，求解导致这种分布的最佳模型参数，使得这种分布出现的概率最大。

对应的二分类的计算公式为：  
      
       
        
        
          l 
         
        
          o 
         
        
          g 
         
        
          l 
         
        
          o 
         
        
          s 
         
        
          s 
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
        
          ( 
         
        
          y 
         
        
          ∗ 
         
        
          l 
         
        
          o 
         
        
          g 
         
         
         
           p 
          
         
           i 
          
         
        
          + 
         
        
          ( 
         
        
          1 
         
        
          − 
         
        
          y 
         
        
          ) 
         
        
          ∗ 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
        
          1 
         
        
          − 
         
         
         
           p 
          
         
           i 
          
         
        
          ) 
         
        
          ) 
         
        
       
         logloss = -\frac{1}{N}\sum_{i= 1}(y*logp_i + (1-y)*log(1-p_i)) 
        
       
     logloss=−N1​i=1∑​(y∗logpi​+(1−y)∗log(1−pi​)) 多分类计算公式：  
      
       
        
        
          l 
         
        
          o 
         
        
          g 
         
        
          l 
         
        
          o 
         
        
          s 
         
        
          s 
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
         
         
           ∑ 
          
          
          
            j 
           
          
            = 
           
          
            1 
           
          
         
        
          ( 
         
         
         
           y 
          
         
           i 
          
         
        
          j 
         
        
          ∗ 
         
        
          l 
         
        
          o 
         
        
          g 
         
         
         
           p 
          
         
           i 
          
         
        
          j 
         
        
          ) 
         
        
       
         logloss = -\frac{1}{N}\sum_{i= 1}\sum_{j=1}(y_ij * logp_ij) 
        
       
     logloss=−N1​i=1∑​j=1∑​(yi​j∗logpi​j)

logloss 衡量的是预测概率分布和真实概率分布的差异性，其值越小越好，其余AUC不同，对预测概率值非常敏感

## 2、回归指标

### 平均绝对误差

 
      
       
        
        
          M 
         
        
          A 
         
        
          E 
         
        
          = 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
        
          ∣ 
         
         
         
           y 
          
         
           i 
          
         
        
          − 
         
         
         
           p 
          
         
           i 
          
         
        
          ∣ 
         
        
       
         MAE=\frac{1}{N}\sum_{i=1}|y_i-p_i| 
        
       
     MAE=N1​i=1∑​∣yi​−pi​∣ 很好的刻画了预测值和真实值之间的偏差。

### 平均平方差/均方误差

 
      
       
        
        
          M 
         
        
          S 
         
        
          E 
         
        
          = 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
        
          ( 
         
         
         
           y 
          
         
           i 
          
         
        
          − 
         
         
         
           p 
          
         
           i 
          
         
         
         
           ) 
          
         
           2 
          
         
        
       
         MSE=\frac{1}{N}\sum_{i=1}(y_i-p_i)^2 
        
       
     MSE=N1​i=1∑​(yi​−pi​)2

平均误差对异常点较敏感

### 方均根差

 
      
       
        
        
          R 
         
        
          M 
         
        
          S 
         
        
          E 
         
        
          = 
         
         
         
           ( 
          
         
        
          M 
         
        
          S 
         
        
          E 
         
        
          ) 
         
        
       
         RMSE=\sqrt(MSE) 
        
       
     RMSE=( 
            <svg width="400em" height="1.28em" viewbox="0 0 400000 1296" preserveaspectratio="xMinYMin slice"> 
             <path d="M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,
158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067
c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,
175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71
c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,
-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26
s76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z"></path> 
            </svg>​MSE) RMSE代表的是预测值和真实值差值的样本标准差，和MAE比，RMSE对大误差样本有更大的惩罚；但对离群点的敏感，其健壮性不如MAE。 使用RMSE是对数据分布的平均值进行拟合。

## 推荐系统相关指标

### 准确率指标:

准确率。推荐给用户的商品中，属于测试集的比例，  
      
       
        
        
          P 
         
        
          ( 
         
         
         
           L 
          
         
           u 
          
         
        
          ) 
         
        
          = 
         
         
          
           
           
             L 
            
           
             u 
            
           
          
            ⋂ 
           
           
           
             B 
            
           
             u 
            
           
          
          
          
            L 
           
          
            u 
           
          
         
        
       
         P(L_u) = \frac{L_u ⋂ B_u }{L_u} 
        
       
     P(Lu​)=Lu​Lu​⋂Bu​​ 整个测试集的准确率为  
      
       
        
        
          P 
         
        
          ( 
         
         
         
           L 
          
         
           u 
          
         
        
          ) 
         
        
          = 
         
         
         
           1 
          
         
           n 
          
         
         
         
           ∑ 
          
          
          
            u 
           
          
            − 
           
          
            &amp;gt; 
           
          
            U 
           
          
         
        
          P 
         
        
          ( 
         
         
         
           L 
          
         
           u 
          
         
        
          ) 
         
        
       
         P(L_u) = \frac{1}{n}\sum_{u -&amp;gt; U }P(L_u) 
        
       
     P(Lu​)=n1​u−&gt;U∑​P(Lu​)

召回率。测试集中有多少在用户的推荐列表中。数学公式:

 
      
       
        
        
          R 
         
        
          ( 
         
         
         
           L 
          
         
           u 
          
         
        
          ) 
         
        
          = 
         
         
          
           
           
             L 
            
           
             u 
            
           
          
            ⋂ 
           
           
           
             B 
            
           
             u 
            
           
          
          
          
            B 
           
          
            u 
           
          
         
        
       
         R(L_u) = \frac{L_u ⋂ B_u }{B_u} 
        
       
     R(Lu​)=Bu​Lu​⋂Bu​​

整个测试集的召回率为  
      
       
        
         
         
           R 
          
         
           L 
          
         
        
          = 
         
         
         
           1 
          
         
           n 
          
         
         
         
           ∑ 
          
          
          
            u 
           
          
            − 
           
          
            &amp;gt; 
           
          
            U 
           
          
         
        
          R 
         
        
          ( 
         
         
         
           L 
          
         
           u 
          
         
        
          ) 
         
        
       
         R_L = \frac{1}{n}\sum_{u -&amp;gt; U }R(L_u) 
        
       
     RL​=n1​u−&gt;U∑​R(Lu​)

F1值。准确率和召回率的加权，数学公式 Fβ=(1+β2)PRβ2P+R。 Ranking Score。数学公式 R=1|EU|∑uiϵEUpuiM−ku 其中EU 表示测试集中所有的边的集合，如果用户u对商品i在测试集中，则Eui=1，pui表示商品i在用户u的推荐列表中的位置，分母M−ku表示用户u的所有商品数目中除了用户已经购买过的商品外的所有商品。该值越小，说明测试集中的商品越靠前。

Hit ratio。数学公式 HR@K=NumberofHits@K|GT|. 分母是所有的测试集合，分子是每个用户前K个中属于测试集合的个数的总和，该指标衡量是召回率，该指标越大越好。 NDCG。数学定义 NDCG@=Zk∑Ki=12ri−1log2(i+1)。ri表示在第i个位置时的“等级关联性”，一般可以用0/1处理，如果该位置的物品在测试集合中，则ri=1，否则为0。另外ZK是归一化系数，表示后面的那一个累加求和公式的最好情况下的和的倒数，也就是ri=1都满足的情况下的后面那一坨的总和，为了使得NDCG计算出来的数值i都在0-1之内。

交叉熵。这个指标作为其余机器学习的优化目标用的比较多，该指标在https://arxiv.org/pdf/1708.05031.pdf中首先被提出来。论文假设如果用户u购买了物品i,则yui=1否则yui=0，则最终的机器学习的模型的优化目标为 L=−∑(u,i)ϵY⋃Y−(yuilogŷ ui+(1−yui)log(1−ŷ ui)) 。

MAE。该指标对适合对数据集拥有打分进行评估，例如豆瓣影评，上面存在对每个电影的1-5的打分。数学公式 MAE=∑(u,i)ϵEU|yui−ŷ ui||EU| 表示所有测试集中推荐预测的分和实际用户打的分的差异，该值越小越好。

RMSE。该指标同样适用于对评分为数值打分的情景。数学公式 RMSE=∑(u,i)ϵEU(yui−ŷ ui)2|EU|‾‾‾‾‾‾‾‾‾‾‾‾‾√ 含义类似于MAE。 非准确率指标:

该类型的指标重载衡量推荐的结果的“个性化”“多样性”“新颖性”等指标，推荐的的愿景之一就是“千人千面”，推荐给每个人的商品都是只是他本人的兴趣使然，抑或是根据本人兴趣进行扩展的商品集合。至于为什么要进行兴趣扩展，因为“过拟合”同样是推荐系统面临的重要挑战之一，关于推荐系统的“过拟合”现象，在这里不做展开。

Hamming distance. 数学公式 H=1N(N−1)∑(i,j)ϵN,i≠j(1−c(i,j)K) 其中c(i,j)表示用户 i,j 前K个推荐结果中有多少是相同的个数，N表示所有的用户数目。海明距离能够有效衡量两个用户推荐列表的差异，该值越大越说明用户之间的推荐结果越不相同，差异性越大。 Intrasimilarity ，内部相关性。数学公式 I=1N∑uϵU(1K(K−1)∑α≠βsαβ) 其中sαβ表示商品αβ的相似度，相似的计算方式可以是Jaccard系数，皮尔森相关系数，向量余弦法等。对于用户u的推荐列表，如果物品与物品之间的相似度越大，说明推荐给用户的商品比较单一，推荐算法越发现不了新的物品；反之，如果该值越小，则推荐的物品越丰富，越有利于对用户的兴趣进行扩展。 Popularity，流行度指标。数学公式 N=1N∑αϵOuRdαK 其中OuR表示用户u的前K个推荐物品的集合，dα表示α的被多少用户购买过，购买次数越多，则该商品越流行。该指标越大，说明推荐算法倾向于推荐“热度”越大、越流行的商品；反之，则越倾向于推荐比较冷门的物品，越能反映出用户的兴趣。
