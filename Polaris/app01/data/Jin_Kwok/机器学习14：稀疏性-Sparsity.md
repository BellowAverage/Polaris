
--- 
title:  机器学习14：稀疏性-Sparsity 
tags: []
categories: [] 

---
现实世界中，问题的特征的数量往往是很大的，而其中起决定性作用的往往是很小的一部分，稀疏规则化算子的引入会学习去掉这些没有信息的特征，也就是把这些特征对应的权重置为 0。

### 1.稀疏性正则化：L₁ 正则化

稀疏向量通常包含许多维度，而创建  则会产生更多维度。考虑到如此高维的特征向量，模型可能会变得巨大且需要大量的 RAM 资源。

在高维稀疏向量中，最好将权重精确地下降到 `0`。权重恰好为 0 本质上意味着从模型中删除相应的特征，即该特征不再作为模型的输入。此外，将特征归零可节省 RAM，并减少模型中的噪声。

例如，考虑一个不仅涵盖加利福尼亚州而且涵盖整个全球的住房数据集。以分（角分）级别（每度 60 分）存储全球纬度，在稀疏编码中提供大约 10,000 个维度；分级别的全球经度给出了大约 20,000 个维度。这两个特征的特征交叉将产生大约 200,000,000 个维度。这 200,000,000 个维度中的许多维度代表的居住区域非常有限（例如海洋中的位置）&amp;#
