
--- 
title:  完美抠图王冰冰！字节实习生实现4K60帧视频实时抠图，连头发丝都根根分明！... 
tags: []
categories: [] 

---
来源：RAVV前沿科技

看这一头蓬松的秀发，加上帅气的动作，你以为是在绿幕前拍大片？

<img src="https://img-blog.csdnimg.cn/img_convert/8f5dc7226d5c8a2430a700042843c1d4.gif">

No、No、No这其实是AI拿来视频实时抠图后的效果。

没想到吧，实时视频抠图，现在能精细到每一根发丝。

<img src="https://img-blog.csdnimg.cn/img_convert/28ef2f70bc59031fbfabc4bab24d7af3.gif">

换到alpha通道再看一眼，不用多说，德芙打钱吧（手动狗头）。

<img src="https://img-blog.csdnimg.cn/img_convert/d0178f426217040b11d4ff4b27763a87.gif">

这就是来自字节跳动实习生小哥的最新研究：实时高分辨率视频抠图大法。

无需任何辅助输入，把视频丢给这个名为RVM的AI，它分分钟就能帮你把人像高精度抠出，将背景替换成可以任意二次加工的绿幕。

<img src="https://img-blog.csdnimg.cn/img_convert/fa592d1d4412c89f5810f184ac819a7e.gif">

不信有这么丝滑？我们用线上Demo亲自尝试了一波。

<img src="https://img-blog.csdnimg.cn/img_convert/518108185416baba32f9287a495f0dbf.gif">

相比之下，现在在线会议软件里的抠图，一旦头发遮住脸，人就会消失……

<img src="https://img-blog.csdnimg.cn/img_convert/5cd0386b04fc6e2868430baf5a8389dc.gif">

头发丝更是明显糊了。

<img src="https://img-blog.csdnimg.cn/img_convert/b0ea994e51eda82154977f2b56318b44.png">

难怪看得网友直言：不敢想象你们把这只AI塞进手机里的样子。

目前，这篇论文已经入选WACV 2022。

   

**你也可以上手一试**

   

目前，RVM已经在GitHub上开源，并给出了两种试玩途径：

<img src="https://img-blog.csdnimg.cn/img_convert/f5b5737327030abf2202261605fcce82.png">

于是我们也赶紧上手试了试。

先来看看效果：

<img src="https://img-blog.csdnimg.cn/img_convert/b82fdade9cc1f4067eed4ba1157a9a5b.gif">

首先来点难度低的。

对于这种人物在画面中基本不移动的情况，RVM可以说是表现的非常好，和人工抠图几乎无差别。

现在，王冰冰进入动森都毫不违和了。

<img src="https://img-blog.csdnimg.cn/img_convert/c4f09210cf88351b66638fdbb2d05487.gif">

于是开脑洞，也变得简单了许多……

<img src="https://img-blog.csdnimg.cn/img_convert/aba6098324219191679cfa7d8a905df6.gif">

咳咳，言归正传。人物动作幅度加大会怎样呢？

<img src="https://img-blog.csdnimg.cn/img_convert/071e4621b32ad338b65c9784d7e663fe.gif">

对于多人舞蹈视频而言，RVM的表现也很nice。即便动来动去、头发乱甩，也没有影响它的抠图效果。

只有在人物出现遮挡的情况下，才会出现瑕疵。对比前辈方法MODNet，确实有不小的进步。

<img src="https://img-blog.csdnimg.cn/img_convert/4f559db8be8d446ac771abfe9a63b08b.gif">

不过我们也发现，如果视频的背景较暗，就会影响RVM的发挥。

比如在这种背景光线昏暗的情况下，抠图的效果就非常不尽人意了。

<img src="https://img-blog.csdnimg.cn/img_convert/ff15ea6ed63659fff380dd56b89de792.png">

可以看到，博主老哥的头发完全糊了。而且身体的边界线也不够清晰。

<img src="https://img-blog.csdnimg.cn/img_convert/c5b42dfc46b9c070cad43b4b6aa64185.gif">

所以，如果你想自己拍视频试玩，就一定要选择光线充足的场景。

   

**利用时间信息**

   

那么这样的“魔法”，具体又是如何实现的？照例，我们先来扒一扒论文~

<img src="https://img-blog.csdnimg.cn/img_convert/4f99741979c1dc5b04b3dd4b5e4c20d8.png">

实际上，有关视频抠图的算法如今已不鲜见，其中大多数采用的是将视频中的每一帧作为独立图像来实现抠图的方法。

不同与此，在这篇论文中，研究人员构建了一个循环架构，利用上了视频的时间信息，在时间一致性和抠图质量上取得了明显改进。

<img src="https://img-blog.csdnimg.cn/img_convert/98011af8798b0ee9075bf95f7a1897d6.png">

从上图中可以看出，RVM的网络架构包括3个部分：

特征提取编码器，用来提取单帧特征；

循环解码器，用于汇总时间信息；

深度引导滤波（DGF）模块，用于高分辨率上采样。

其中，循环机制的引入使得AI能够在连续的视频流中自我学习，从而了解到哪些信息需要保留，哪些信息可以遗忘掉。

具体而言，循环解码器采用了多尺度ConvGRU来聚合时间信息。其定义如下：

<img src="https://img-blog.csdnimg.cn/img_convert/6b368f76dda5c0ae6eb2e5b21dc44dca.png">

在这个编码器-解码器网络中，AI会完成对高分辨率视频的下采样，然后再使用DGF对结果进行上采样。

除此之外，研究人员还提出了一种新的训练策略：同时使用抠图和语义分割目标数据集来训练网络。

这样做到好处在于：首先，人像抠图与人像分割任务密切相关，AI必须学会从语义上理解场景，才能在定位人物主体方面具备鲁棒性。

其次，现有的大部分抠图数据集只提供真实的alpha通道和前景信息，所以必须对背景图像进行合成。但前景和背景的光照往往不同，这就影响了合成的效果。语义分割数据集的引入可以有效防止过拟合。

最后，语义分割数据集拥有更为丰富的训练数据。

经过这一番调教之后，RVM和前辈们比起来，有怎样的改进？

从效果对比中就可以明显感受到了：

<img src="https://img-blog.csdnimg.cn/img_convert/b4f1a744e5970e101ecd0cdf518ce898.gif">

另外，与MODNet相比，RVM更轻更快。

<img src="https://img-blog.csdnimg.cn/img_convert/1d8e5bcd2a5ae9c3e649c2d97eaf49ec.png">

从下面这张表格中可以看出，在1080p视频上RVM的处理速度是最快的，在512×288上比BGMv2略慢，在4K视频上则比带FGF的MODNet慢一点。研究人员分析，这是因为RVM除了alpha通道外还预判了前景。

<img src="https://img-blog.csdnimg.cn/img_convert/bf445bbc7e89240e4cdfb3f3c79c26a3.png">

更直观的数据是，在英伟达GTX 1080Ti上，RVM能以76FPS的速度处理4K视频，以104FPS的速度处理HD视频。

**讲在最后  **

对了，除了能在Colab上试用之外，你也可以在网页版上实时感受一下这只AI的效果，地址拿好：

https://peterl1n.github.io/RobustVideoMatting/#/demo

GitHub地址：https://github.com/PeterL1n/RobustVideoMatting

论文地址：https://arxiv.org/abs/2108.11515

参考链接：

https://www.reddit.com/r/MachineLearning/comments/pdbpmg/r_robust_highresolution_video_matting_with/

&lt; END &gt;

<img src="https://img-blog.csdnimg.cn/img_convert/548a955aece0bbd7f83194d7710a582a.gif">

微信扫码关注，了解更多内容
