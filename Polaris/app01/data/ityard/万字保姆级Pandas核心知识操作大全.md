
--- 
title:  ä¸‡å­—ä¿å§†çº§Pandasæ ¸å¿ƒçŸ¥è¯†æ“ä½œå¤§å…¨ 
tags: []
categories: [] 

---
ğŸ‘†ç‚¹å‡»å…³æ³¨ï½œè®¾ä¸ºæ˜Ÿæ ‡ï½œå¹²è´§é€Ÿé€’ğŸ‘†

åˆ†äº«æœ€è¿‘å¸¸ç”¨åˆ°pandasåšæ•°æ®å¤„ç†å’Œåˆ†æï¼Œç‰¹æ„æ€»ç»“äº†ä»¥ä¸‹å¸¸ç”¨å†…å®¹ã€‚

### pandaså¸¸ç”¨é€ŸæŸ¥

#### å¼•å…¥ä¾èµ–

```
#Â å¯¼å…¥æ¨¡å—
importÂ pymysql
importÂ pandasÂ asÂ pd
importÂ numpyÂ asÂ np
importÂ time

#Â æ•°æ®åº“
fromÂ sqlalchemyÂ importÂ create_engine

#Â å¯è§†åŒ–
importÂ matplotlib.pyplotÂ asÂ plt
#Â å¦‚æœä½ çš„è®¾å¤‡æ˜¯é…å¤‡Retinaå±å¹•çš„macï¼Œå¯ä»¥åœ¨jupyterÂ notebookä¸­ï¼Œä½¿ç”¨ä¸‹é¢ä¸€è¡Œä»£ç æœ‰æ•ˆæé«˜å›¾åƒç”»è´¨
%configÂ InlineBackend.figure_formatÂ =Â 'retina'
#Â è§£å†³Â pltÂ ä¸­æ–‡æ˜¾ç¤ºçš„é—®é¢˜Â mymac
plt.rcParams['font.sans-serif']Â =Â ['ArialÂ UnicodeÂ MS']
#Â è®¾ç½®æ˜¾ç¤ºä¸­æ–‡Â éœ€è¦å…ˆå®‰è£…å­—ä½“Â aistudio
plt.rcParams['font.sans-serif']Â =Â ['SimHei']Â #Â æŒ‡å®šé»˜è®¤å­—ä½“
plt.rcParams['axes.unicode_minus']Â =Â FalseÂ Â #Â ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
importÂ seabornÂ asÂ sns
#Â notebookæ¸²æŸ“å›¾ç‰‡
%matplotlibÂ inline
importÂ pyecharts

#Â å¿½ç•¥ç‰ˆæœ¬é—®é¢˜
importÂ warnings
warnings.filterwarnings("ignore")
```

```
#Â ä¸‹è½½ä¸­æ–‡å­—ä½“
!wgetÂ https://mydueros.cdn.bcebos.com/font/simhei.ttfÂ 
#Â å°†å­—ä½“æ–‡ä»¶å¤åˆ¶åˆ°Â matplotlib'å­—ä½“è·¯å¾„
!cpÂ simhei.ttfÂ /opt/conda/envs/python35-paddle120-env/Lib/python3,7/site-packages/matplotib/mpl-data/fonts.

#Â ä¸€èˆ¬åªéœ€è¦å°†å­—ä½“æ–‡ä»¶å¤åˆ¶åˆ°ç³»ç»Ÿå­—ä½“ç”°å½•ä¸‹å³å¯,ä½†æ˜¯åœ¨Â studioä¸Šè¯¥è·¯å¾„æ²¡æœ‰å†™æƒé™,æ‰€ä»¥æ­¤æ–¹æ³•ä¸èƒ½ç”¨Â 
#Â !cpÂ simhei.Â ttfÂ /usr/share/fonts/

#Â åˆ›å»ºç³»ç»Ÿå­—ä½“æ–‡ä»¶è·¯å¾„
!mkdirÂ .fonts
#Â å¤åˆ¶æ–‡ä»¶åˆ°è¯¥è·¯å¾„
!cpÂ simhei.ttfÂ .fonts/
!rmÂ -rfÂ .cache/matplotlib
```

<img src="https://img-blog.csdnimg.cn/img_convert/4e439db42021f970b839e166f7445ef6.png" alt="4e439db42021f970b839e166f7445ef6.png">

#### ç®—æ³•ç›¸å…³ä¾èµ–

```
#Â æ•°æ®å½’ä¸€åŒ–
fromÂ sklearn.preprocessingÂ importÂ MinMaxScaler

#Â kmeansèšç±»
fromÂ sklearn.clusterÂ importÂ KMeans
#Â DBSCANèšç±»
fromÂ sklearn.clusterÂ importÂ DBSCAN
#Â çº¿æ€§å›å½’ç®—æ³•
fromÂ sklearn.linear_modelÂ importÂ LinearRegression
#Â é€»è¾‘å›å½’ç®—æ³•
fromÂ sklearn.linear_modelÂ importÂ LogisticRegression
#Â é«˜æ–¯è´å¶æ–¯
fromÂ sklearn.naive_bayesÂ importÂ GaussianNB
#Â åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
fromÂ sklearn.model_selectionÂ importÂ train_test_split
#Â å‡†ç¡®åº¦æŠ¥å‘Š
fromÂ sklearnÂ importÂ metrics
#Â çŸ©é˜µæŠ¥å‘Šå’Œå‡æ–¹è¯¯å·®
fromÂ sklearn.metricsÂ importÂ classification_report,Â mean_squared_error
```

#### è·å–æ•°æ®

```
fromÂ sqlalchemyÂ importÂ create_engine
engineÂ =Â create_engine('mysql+pymysql://root:root@127.0.0.1:3306/ry?charset=utf8')

#Â æŸ¥è¯¢æ’å…¥åç›¸å…³è¡¨ååŠè¡Œæ•°
result_query_sqlÂ =Â "useÂ information_schema;"
engine.execute(result_query_sql)
result_query_sqlÂ =Â "SELECTÂ table_name,table_rowsÂ FROMÂ tablesÂ WHEREÂ TABLE_NAMEÂ LIKEÂ 'log%%'Â orderÂ byÂ table_rowsÂ desc;"
df_resultÂ =Â pd.read_sql(result_query_sql,Â engine)
```

<img src="https://img-blog.csdnimg.cn/img_convert/3356bbc949cfc59c0dca0308a7cb2810.png" alt="3356bbc949cfc59c0dca0308a7cb2810.png">

#### ç”Ÿæˆdf

```
#Â listè½¬df
df_resultÂ =Â pd.DataFrame(pred,columns=['pred'])
df_result['actual']Â =Â test_target
df_result

#Â dfå–å­df
df_newÂ =Â df_old[['col1','col2']]

#Â dictç”Ÿæˆdf
df_testÂ =Â pd.DataFrame({'A':[0.587221,Â 0.135673,Â 0.135673,Â 0.135673,Â 0.135673],Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'B':['a',Â 'b',Â 'c',Â 'd',Â 'e'],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'C':[1,Â 2,Â 3,Â 4,Â 5]})

#Â æŒ‡å®šåˆ—å
dataÂ =Â pd.DataFrame(dataset.data,Â columns=dataset.feature_names)

#Â ä½¿ç”¨numpyç”Ÿæˆ20ä¸ªæŒ‡å®šåˆ†å¸ƒ(å¦‚æ ‡å‡†æ­£æ€åˆ†å¸ƒ)çš„æ•°
temÂ =Â np.random.normal(0,Â 1,Â 20)
df3Â =Â pd.DataFrame(tem)

#Â ç”Ÿæˆä¸€ä¸ªå’Œdfé•¿åº¦ç›¸åŒçš„éšæœºæ•°dataframe
df1Â =Â pd.DataFrame(pd.Series(np.random.randint(1,Â 10,Â 135)))
```

#### é‡å‘½ååˆ—

```
#Â é‡å‘½ååˆ—
data_scaledÂ =Â data_scaled.rename(columns={'æœ¬ä½“æ²¹ä½':Â 'OILLV'})
```

#### å¢åŠ åˆ—

```
#Â df2df
df_jj2yyb['r_time']Â =Â pd.to_datetime(df_jj2yyb['cTime'])

#Â æ–°å¢ä¸€åˆ—æ ¹æ®salaryå°†æ•°æ®åˆ†ä¸º3ç»„
binsÂ =Â [0,5000,Â 20000,Â 50000]
group_namesÂ =Â ['ä½',Â 'ä¸­',Â 'é«˜']
df['categories']Â =Â pd.cut(df['salary'],Â bins,Â labels=group_names)
```

#### ç¼ºå¤±å€¼å¤„ç†

```
#Â æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦å«æœ‰ä»»ä½•ç¼ºå¤±å€¼
df.isnull().values.any()

#Â æŸ¥çœ‹æ¯åˆ—æ•°æ®ç¼ºå¤±å€¼æƒ…å†µ
df.isnull().sum()

#Â æå–æŸåˆ—å«æœ‰ç©ºå€¼çš„è¡Œ
df[df['æ—¥æœŸ'].isnull()]

#Â è¾“å‡ºæ¯åˆ—ç¼ºå¤±å€¼å…·ä½“è¡Œæ•°
forÂ iÂ inÂ df.columns:
Â Â Â Â ifÂ df[i].count()Â !=Â len(df):
Â Â Â Â Â Â Â Â rowÂ =Â df[i][df[i].isnull().values].index.tolist()
Â Â Â Â Â Â Â Â print('åˆ—åï¼š"{}", ç¬¬{}è¡Œä½ç½®æœ‰ç¼ºå¤±å€¼'.format(i,row))

#Â ä¼—æ•°å¡«å……
heart_df['Thal'].fillna(heart_df['Thal'].mode(dropna=True)[0],Â inplace=True)

#Â è¿ç»­å€¼åˆ—çš„ç©ºå€¼ç”¨å¹³å‡å€¼å¡«å……
dfcolumnsÂ =Â heart_df_encoded.columns.values.tolist()
forÂ itemÂ inÂ dfcolumns:
Â Â Â Â ifÂ heart_df_encoded[item].dtypeÂ ==Â 'float':
Â Â Â Â Â Â Â heart_df_encoded[item].fillna(heart_df_encoded[item].median(),Â inplace=True)
```

#### ç‹¬çƒ­ç¼–ç 

```
df_encodedÂ =Â pd.get_dummies(df_data)
```

#### æ›¿æ¢å€¼

```
#Â æŒ‰åˆ—å€¼æ›¿æ¢
num_encodeÂ =Â {
Â Â Â Â 'AHD':Â {'No':0,Â "Yes":1},
}
heart_df.replace(num_encode,inplace=True)
```

#### åˆ é™¤åˆ—

```
df_jj2.drop(['coll_time',Â 'polar',Â 'conn_type',Â 'phase',Â 'id',Â 'Unnamed:Â 0'],axis=1,inplace=True)
```

#### groupby

```
#Â 0.ä»sklearnåŠ è½½irisæ•°æ®é›†
fromÂ sklearnÂ importÂ datasets
#Â åŠ è½½æ•°æ®é›†å’Œç›®æ ‡
data,Â targetÂ =Â datasets.load_iris(return_X_y=True,Â as_frame=True)
#Â åˆå¹¶æ•°æ®é›†å’Œç›®æ ‡
irisÂ =Â pd.concat([data,Â target],Â axis=1,Â sort=False)
iris

#Â åˆ›å»ºgroupbyå¯¹è±¡
iris_gbÂ =Â iris.groupby('target')

#Â 1.Â åˆ›å»ºé¢‘ç‡è¡¨ï¼Œè¾“å‡ºæ¯ä¸ªç±»ä¸­æ•°é‡å¤šå°‘
iris_gb.size()

#Â 2.Â è®¡ç®—å¸¸ç”¨çš„æè¿°ç»Ÿè®¡é‡
#Â minã€max()ã€medianheã€stdç­‰
#Â è®¡ç®—å‡å€¼
iris_gb.mean()
#Â å•åˆ—
iris_gb['sepalÂ lengthÂ (cm)'].mean()
#Â åŒåˆ—
iris_gb[['sepalÂ lengthÂ (cm)',Â 'sepalÂ widthÂ (cm)']].mean()

#Â 3.Â æŸ¥æ‰¾æœ€å¤§å€¼ï¼ˆæœ€å°å€¼ï¼‰ç´¢å¼•
iris_gb.idxmax()

#Â æŒ‰sepal_lengthæœ€å¤§å€¼è¿™ä¸ªæ¡ä»¶è¿›è¡Œäº†ç­›é€‰
sepal_largestÂ =Â iris.loc[iris_gb['sepalÂ lengthÂ (cm)'].idxmax()]

#Â 4.Â Groupbyä¹‹åé‡ç½®ç´¢å¼•
iris_gb.max().reset_index()
#Â â†‘â†“äºŒè€…æ•ˆæœç›¸åŒ
iris.groupby('target',Â as_index=False).max()

#Â 5.Â å¤šç§ç»Ÿè®¡é‡æ±‡æ€»ï¼Œèšåˆå‡½æ•°agg
iris_gb[['sepalÂ lengthÂ (cm)',Â 'sepalÂ widthÂ (cm)']].agg(["min",Â "mean"])

#Â 6.ç‰¹å®šåˆ—çš„èšåˆ
#Â ä¸ºä¸åŒçš„åˆ—å•ç‹¬è®¾ç½®ä¸åŒçš„ç»Ÿè®¡é‡
iris_gb.agg({"sepalÂ lengthÂ (cm)":Â ["min",Â "max"],Â "sepalÂ widthÂ (cm)":Â ["mean",Â "std"]})

#Â 7.Â NamedAggå‘½åç»Ÿè®¡é‡
#Â æŠŠæ¯ä¸ªåˆ—ä¸‹é¢çš„ç»Ÿè®¡é‡å’Œåˆ—ååˆ†åˆ«åˆå¹¶èµ·æ¥ã€‚å¯ä»¥ä½¿ç”¨NamedAggæ¥å®Œæˆåˆ—çš„å‘½å

iris_gb.agg(
Â Â Â Â Â sepal_min=pd.NamedAgg(column="sepalÂ lengthÂ (cm)",Â aggfunc="min"),
Â Â Â Â Â sepal_max=pd.NamedAgg(column="sepalÂ lengthÂ (cm)",Â aggfunc="max"),
Â Â Â Â Â petal_mean=pd.NamedAgg(column="petalÂ lengthÂ (cm)",Â aggfunc="mean"),
Â Â Â Â Â petal_std=pd.NamedAgg(column="petalÂ lengthÂ (cm)",Â aggfunc="std")
Â )

#Â ä¸‹è¿°æ›´ç®€æ´
iris_gb.agg(
Â Â Â Â sepal_min=("sepalÂ lengthÂ (cm)",Â "min"),
Â Â Â Â sepal_max=("sepalÂ lengthÂ (cm)",Â "max"),
Â Â Â Â petal_mean=("petalÂ lengthÂ (cm)",Â "mean"),
Â Â Â Â petal_std=("petalÂ lengthÂ (cm)",Â "std")
)

#Â 8.Â ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
iris_gb.agg(pd.Series.mean)
#Â ä¸ä»…å¦‚æ­¤ï¼Œåç§°å’ŒåŠŸèƒ½å¯¹è±¡ä¹Ÿå¯ä¸€èµ·ä½¿ç”¨ã€‚
iris_gb.agg(["min",Â pd.Series.mean])
#Â æˆ‘ä»¬è¿˜å¯ä»¥è‡ªå®šä¹‰å‡½æ•°ï¼Œä¹Ÿéƒ½æ˜¯å¯ä»¥çš„ã€‚
defÂ double_length(x):
Â Â Â Â returnÂ 2*x.mean()

iris_gb.agg(double_length)
#Â å¦‚æœæƒ³æ›´ç®€æ´ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨lambdaå‡½æ•°ã€‚æ€»ä¹‹ï¼Œç”¨æ³•éå¸¸çµæ´»ï¼Œå¯ä»¥è‡ªç”±ç»„åˆæ­é…ã€‚
iris_gb.agg(lambdaÂ x:Â x.mean())
```

#### é€è§†è¡¨

```
importÂ numpyÂ asÂ np
importÂ pandasÂ asÂ pd
importÂ seabornÂ asÂ sns
titanicÂ =Â sns.load_dataset('titanic')

titanic.pivot_table(index='sex',Â columns='class')

#Â é»˜è®¤å¯¹æ‰€æœ‰åˆ—è¿›è¡Œèšåˆï¼Œè¿™æ—¶æˆ‘ä»¬ç»™ä¸valueså‚æ•°ï¼Œåªè®¡ç®—æƒ³è¦çš„ç»“æœ
aggÂ =Â pd.cut(titanic["age"],[0,18,80])Â #Â å¯¹å¹´é¾„æ•°æ®åˆ—è¿›è¡Œåˆ†æ®µï¼Œä¾¿äºè§‚çœ‹
titanic.pivot_table(index=['sex','age'],Â columns='class',values=['survived','fare'])

#Â åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¹¶ä¸ä¸€å®šæ¯æ¬¡éƒ½è¦å‡å€¼ï¼Œä½¿ç”¨aggfuncæŒ‡å®šç´¯è®¡å‡½æ•°
titanic.pivot_table(index='sex',Â columns='class',aggfunc={'survived':sum,Â 'fare':'mean'})

#Â å½“éœ€è¦è®¡ç®—æ¯ä¸€ç»„çš„æ€»æ•°æ—¶ï¼Œå¯ä»¥é€šè¿‡margins å‚æ•°æ¥è®¾ç½®ï¼š
# margin çš„æ ‡ç­¾å¯ä»¥é€šè¿‡margins_name å‚æ•°è¿›è¡Œè‡ªå®šä¹‰ï¼Œé»˜è®¤å€¼æ˜¯"All"ã€‚
titanic.pivot_table('survived',Â index='sex',Â columns='class',Â margins=True)
```

#### æ•°æ®ç­›é€‰

```
#Â å–ç¬¬33è¡Œæ•°æ®
df.iloc[32]

#Â æŸåˆ—ä»¥xxxå­—ç¬¦ä¸²å¼€å¤´
df_jj2Â =Â df_512.loc[df_512["transformer"].str.startswith('JJ2')]

df_jj2yyaÂ =Â df_jj2.loc[df_jj2["å˜å‹å™¨ç¼–å·"]=='JJ2YYA']

#Â æå–ç¬¬ä¸€åˆ—ä¸­ä¸åœ¨ç¬¬äºŒåˆ—å‡ºç°çš„æ•°å­—
df['col1'][~df['col1'].isin(df['col2'])]

#Â æŸ¥æ‰¾ä¸¤åˆ—å€¼ç›¸ç­‰çš„è¡Œå·
np.where(df.secondTypeÂ ==Â df.thirdType)

#Â åŒ…å«å­—ç¬¦ä¸²
resultsÂ =Â df['grammer'].str.contains("Python")

#Â æå–åˆ—å
df.columns

#Â æŸ¥çœ‹æŸåˆ—å”¯ä¸€å€¼ï¼ˆç§ç±»ï¼‰
df['education'].nunique()

#Â åˆ é™¤é‡å¤æ•°æ®
df.drop_duplicates(inplace=True)

#Â æŸåˆ—ç­‰äºæŸå€¼
df[df.col_name==0.587221]
#Â df.col_name==0.587221Â å„è¡Œåˆ¤æ–­ç»“æœè¿”å›å€¼(True/False)

#Â æŸ¥çœ‹æŸåˆ—å”¯ä¸€å€¼åŠè®¡æ•°
df_jj2["å˜å‹å™¨ç¼–å·"].value_counts()

#Â æ—¶é—´æ®µç­›é€‰
df_jj2yyb_0501_0701Â =Â df_jj2yyb[(df_jj2yyb['r_time']Â &gt;=pd.to_datetime('20200501'))Â &amp;Â (df_jj2yyb['r_time']Â &lt;=Â pd.to_datetime('20200701'))]

#Â æ•°å€¼ç­›é€‰
df[(df['popularity']Â &gt;Â 3)Â &amp;Â (df['popularity']Â &lt;Â 7)]

#Â æŒ‰æ•°æ®ç±»å‹é€‰æ‹©åˆ—
dfÂ =Â pd.DataFrame({'a':Â [1,Â 2]Â *Â 3,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'b':Â [True,Â False]Â *Â 3,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 'c':Â [1.0,Â 2.0]Â *Â 3})
print('df:',Â df)

#Â è¾“å‡ºåŒ…å«Â boolÂ æ•°æ®ç±»å‹çš„åˆ—
print('è¾“å‡ºåŒ…å«Â boolÂ æ•°æ®ç±»å‹çš„åˆ—:',Â df.select_dtypes(include='bool'))

#Â è¾“å‡ºåŒ…å«å°æ•°æ•°æ®ç±»å‹çš„åˆ—
print('è¾“å‡ºåŒ…å«å°æ•°æ•°æ®ç±»å‹çš„åˆ—:',Â df.select_dtypes(include=['float64']))

#Â è¾“å‡ºæ’é™¤æ•´æ•°çš„åˆ—
print('è¾“å‡ºåŒ…å«å°æ•°æ•°æ®ç±»å‹çš„åˆ—:',Â df.select_dtypes(exclude=['int64']))

#Â æŸåˆ—å­—ç¬¦ä¸²æˆªå–
df['Time'].str[0:8]

#Â éšæœºå–numè¡Œ
ins_1Â =Â df.sample(n=num)

#Â æ•°æ®å»é‡
df.drop_duplicates(['grammer'])

#Â æŒ‰æŸåˆ—æ’åº(é™åº)
df.sort_values("popularity",inplace=True,Â ascending=False)

#Â å–æŸåˆ—æœ€å¤§å€¼æ‰€åœ¨è¡Œ
df[df['popularity']Â ==Â df['popularity'].max()]

#Â å–æŸåˆ—æœ€å¤§numè¡Œ
df.nlargest(num,'col_name')
#Â æœ€å¤§numåˆ—ç”»æ¨ªå‘æŸ±å½¢å›¾
df.nlargest(10).plot(kind='barh')
```

<img src="https://img-blog.csdnimg.cn/img_convert/9188560f5f75b57f5499baa198ac2e07.png" alt="9188560f5f75b57f5499baa198ac2e07.png">

#### å·®å€¼è®¡ç®—

```
# axis=0æˆ–indexè¡¨ç¤ºä¸Šä¸‹ç§»åŠ¨ï¼Œ periodsè¡¨ç¤ºç§»åŠ¨çš„æ¬¡æ•°ï¼Œä¸ºæ­£æ—¶å‘ä¸‹ç§»ï¼Œä¸ºè´Ÿæ—¶å‘ä¸Šç§»åŠ¨ã€‚
print(df.diff(Â periods=1,Â axis=â€˜indexâ€˜))
print(df.diff(Â periods=-1,Â axis=0))
# axis=1æˆ–columnsè¡¨ç¤ºå·¦å³ç§»åŠ¨ï¼Œperiodsè¡¨ç¤ºç§»åŠ¨çš„æ¬¡æ•°ï¼Œä¸ºæ­£æ—¶å‘å³ç§»ï¼Œä¸ºè´Ÿæ—¶å‘å·¦ç§»åŠ¨ã€‚
print(df.diff(Â periods=1,Â axis=â€˜columnsâ€˜))
print(df.diff(Â periods=-1,Â axis=1))

#Â å˜åŒ–ç‡è®¡ç®—
data['æ”¶ç›˜ä»·(å…ƒ)'].pct_change()

#Â ä»¥5ä¸ªæ•°æ®ä½œä¸ºä¸€ä¸ªæ•°æ®æ»‘åŠ¨çª—å£ï¼Œåœ¨è¿™ä¸ª5ä¸ªæ•°æ®ä¸Šå–å‡å€¼
df['æ”¶ç›˜ä»·(å…ƒ)'].rolling(5).mean()
```

#### æ•°æ®ä¿®æ”¹

```
#Â åˆ é™¤æœ€åä¸€è¡Œ
dfÂ =Â df.drop(labels=df.shape[0]-1)

#Â æ·»åŠ ä¸€è¡Œæ•°æ®['Perl',6.6]
rowÂ =Â {'grammer':'Perl','popularity':6.6}
dfÂ =Â df.append(row,ignore_index=True)

#Â æŸåˆ—å°æ•°è½¬ç™¾åˆ†æ•°
df.style.format({'data':Â '{0:.2%}'.format})

#Â åè½¬è¡Œ
df.iloc[::-1,Â :]

#Â ä»¥ä¸¤åˆ—åˆ¶ä½œæ•°æ®é€è§†
pd.pivot_table(df,values=["salary","score"],index="positionId")

#Â åŒæ—¶å¯¹ä¸¤åˆ—è¿›è¡Œè®¡ç®—
df[["salary","score"]].agg([np.sum,np.mean,np.min])

#Â å¯¹ä¸åŒåˆ—æ‰§è¡Œä¸åŒçš„è®¡ç®—
df.agg({"salary":np.sum,"score":np.mean})
```

#### æ—¶é—´æ ¼å¼è½¬æ¢

```
#Â æ—¶é—´æˆ³è½¬æ—¶é—´å­—ç¬¦ä¸²
df_jj2['cTime']Â =df_jj2['coll_time'].apply(lambdaÂ x:Â time.strftime("%Y-%m-%dÂ %H:%M:%S",Â time.localtime(x)))

#Â æ—¶é—´å­—ç¬¦ä¸²è½¬æ—¶é—´æ ¼å¼
df_jj2yyb['r_time']Â =Â pd.to_datetime(df_jj2yyb['cTime'])

#Â æ—¶é—´æ ¼å¼è½¬æ—¶é—´æˆ³
dtimeÂ =Â pd.to_datetime(df_jj2yyb['r_time'])
vÂ =Â (dtime.valuesÂ -Â np.datetime64('1970-01-01T08:00:00Z'))Â /Â np.timedelta64(1,Â 'ms')
df_jj2yyb['timestamp']Â =Â v
```

#### è®¾ç½®ç´¢å¼•åˆ—

```
df_jj2yyb_small_noiseÂ =Â df_jj2yyb_small_noise.set_index('timestamp')
```

#### æŠ˜çº¿å›¾

```
fig,Â axÂ =Â plt.subplots()
df.plot(legend=True,Â ax=ax)
plt.legend(loc=1)
plt.show()
```

<img src="https://img-blog.csdnimg.cn/img_convert/b9feee1cad7e0d08ac1ca60b3e55169c.png" alt="b9feee1cad7e0d08ac1ca60b3e55169c.png">

```
plt.figure(figsize=(20,Â 6))
plt.plot(max_iter_list,Â accuracy,Â color='red',Â marker='o',
Â Â Â Â Â Â Â Â Â markersize=10)
plt.title('AccuracyÂ VsÂ max_iterÂ Value')
plt.xlabel('max_iterÂ Value')
plt.ylabel('Accuracy')
```

<img src="https://img-blog.csdnimg.cn/img_convert/7695e4e3bdbf5dac82aa53d49f21045a.png" alt="7695e4e3bdbf5dac82aa53d49f21045a.png">

#### æ•£ç‚¹å›¾

```
plt.scatter(df[:,Â 0],Â df[:,Â 1],Â c="red",Â marker='o',Â label='lable0')Â Â Â 
plt.xlabel('x')Â Â 
plt.ylabel('y')Â Â 
plt.legend(loc=2)Â Â 
plt.show()
```

<img src="https://img-blog.csdnimg.cn/img_convert/2de7e6100071bdd9414c538049ff3684.png" alt="2de7e6100071bdd9414c538049ff3684.png">

#### æŸ±å½¢å›¾

```
dfÂ =Â pd.Series(tree.feature_importances_,Â index=data.columns)
#Â å–æŸåˆ—æœ€å¤§Numè¡Œç”»æ¨ªå‘æŸ±å½¢å›¾
df.nlargest(10).plot(kind='barh')
```

<img src="https://img-blog.csdnimg.cn/img_convert/3c9bf90400bf67f7129b46614379f3cd.png" alt="3c9bf90400bf67f7129b46614379f3cd.png">

#### çƒ­åŠ›å›¾

```
df_corrÂ =Â combine.corr()
plt.figure(figsize=(20,20))
g=sns.heatmap(df_corr,annot=True,cmap="RdYlGn")
```

<img src="https://img-blog.csdnimg.cn/img_convert/3cc507e15af9968241bad7d63c2c368d.png" alt="3cc507e15af9968241bad7d63c2c368d.png">

### 66ä¸ªæœ€å¸¸ç”¨çš„pandasæ•°æ®åˆ†æå‡½æ•°

```
dfÂ #ä»»ä½•pandasÂ DataFrameå¯¹è±¡Â 
sÂ #ä»»ä½•pandasÂ serieså¯¹è±¡
```

#### ä»å„ç§ä¸åŒçš„æ¥æºå’Œæ ¼å¼å¯¼å…¥æ•°æ®

```
pd.read_csv(filename)Â #Â ä»CSVæ–‡ä»¶Â 
pd.read_table(filename)Â #Â ä»åˆ†éš”çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆä¾‹å¦‚CSVï¼‰ä¸­Â 
pd.read_excel(filename)Â #Â ä»Excelæ–‡ä»¶Â 
pd.read_sql(query,Â connection_object)Â #Â ä»SQLè¡¨/æ•°æ®åº“ä¸­è¯»å–Â 
pd.read_json(json_string)Â #Â ä»JSONæ ¼å¼çš„å­—ç¬¦ä¸²ï¼ŒURLæˆ–æ–‡ä»¶ä¸­è¯»å–ã€‚
pd.read_html(url)Â #Â è§£æhtmlÂ URLï¼Œå­—ç¬¦ä¸²æˆ–æ–‡ä»¶ï¼Œå¹¶å°†è¡¨æå–åˆ°æ•°æ®å¸§åˆ—è¡¨Â 
pd.read_clipboard()Â #Â è·å–å‰ªè´´æ¿çš„å†…å®¹å¹¶å°†å…¶ä¼ é€’ç»™Â read_table()Â 
pd.DataFrame(dict)Â #Â ä»å­—å…¸ä¸­ï¼Œåˆ—åç§°çš„é”®ï¼Œåˆ—è¡¨ä¸­çš„æ•°æ®çš„å€¼
```

#### å¯¼å‡ºæ•°æ®

```
df.to_csv(filename)Â #Â å†™å…¥CSVæ–‡ä»¶Â 
df.to_excel(filename)Â #Â å†™å…¥Excelæ–‡ä»¶Â 
df.to_sql(table_name,Â connection_object)Â #Â å†™å…¥SQLè¡¨Â 
df.to_json(filename)Â #Â ä»¥JSONæ ¼å¼å†™å…¥æ–‡ä»¶
```

#### åˆ›å»ºæµ‹è¯•å¯¹è±¡

```
pd.DataFrame(np.random.rand(20,5))Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â 5åˆ—20è¡Œéšæœºæµ®ç‚¹æ•°Â pd.Series(my_list)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â ä»ä¸€ä¸ªå¯è¿­ä»£çš„åºåˆ—åˆ›å»ºä¸€ä¸ªåºåˆ—Â my_listÂ 
df.indexÂ =Â pd.date_range('1900/1/30',Â periods=df.shape[0])Â #Â æ·»åŠ æ—¥æœŸç´¢å¼•
```

#### æŸ¥çœ‹ã€æ£€æŸ¥æ•°æ®

```
df.head(n)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â DataFrameçš„å‰nè¡ŒÂ 
df.tail(n)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â DataFrameçš„æœ€ånè¡ŒÂ 
df.shapeÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â è¡Œæ•°å’Œåˆ—æ•°Â 
df.info()Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â ç´¢å¼•ï¼Œæ•°æ®ç±»å‹å’Œå†…å­˜ä¿¡æ¯Â 
df.describe()Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â æ•°å€¼åˆ—çš„æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯Â 
s.value_counts(dropna=False)Â Â Â Â Â #Â æŸ¥çœ‹å”¯ä¸€å€¼å’Œè®¡æ•°Â 
df.apply(pd.Series.value_counts)Â #Â æ‰€æœ‰åˆ—çš„å”¯ä¸€å€¼å’Œè®¡æ•°
```

#### æ•°æ®é€‰å–

```
ä½¿ç”¨è¿™äº›å‘½ä»¤é€‰æ‹©æ•°æ®çš„ç‰¹å®šå­é›†ã€‚
df[col]Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â è¿”å›å¸¦æœ‰æ ‡ç­¾colçš„åˆ—Â 
df[[col1,Â col2]]Â Â Â Â Â Â #Â è¿”å›åˆ—ä½œä¸ºæ–°çš„DataFrameÂ 
s.iloc[0]Â Â Â Â Â Â Â Â Â Â Â Â Â #Â æŒ‰ä½ç½®é€‰æ‹©Â 
s.loc['index_one']Â Â Â Â #Â æŒ‰ç´¢å¼•é€‰æ‹©Â 
df.iloc[0,:]Â Â Â Â Â Â Â Â Â Â #Â ç¬¬ä¸€è¡ŒÂ 
df.iloc[0,0]Â Â Â Â Â Â Â Â Â Â #Â ç¬¬ä¸€æ çš„ç¬¬ä¸€å…ƒç´ 
```

#### æ•°æ®æ¸…ç†

```
df.columnsÂ =Â ['a','b','c']Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â é‡å‘½ååˆ—Â 
pd.isnull()Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â ç©ºå€¼æ£€æŸ¥ï¼Œè¿”å›BooleanÂ ArrrayÂ 
pd.notnull()Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â ä¸pd.isnull()Â ç›¸åÂ 
df.dropna()Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â åˆ é™¤æ‰€æœ‰åŒ…å«ç©ºå€¼çš„è¡ŒÂ 
df.dropna(axis=1)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â åˆ é™¤æ‰€æœ‰åŒ…å«ç©ºå€¼çš„åˆ—Â 
df.dropna(axis=1,thresh=n)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â åˆ é™¤æ‰€æœ‰å…·æœ‰å°‘äºnä¸ªénullå€¼çš„è¡ŒÂ 
df.fillna(x)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â å°†æ‰€æœ‰ç©ºå€¼æ›¿æ¢ä¸ºxÂ 
s.fillna(s.mean())Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â ç”¨å‡å€¼æ›¿æ¢æ‰€æœ‰ç©ºå€¼ï¼ˆå‡å€¼å¯ä»¥ç”¨ç»Ÿè®¡æ¨¡å—ä¸­çš„å‡ ä¹æ‰€æœ‰å‡½æ•°æ›¿æ¢Â ï¼‰Â 
s.astype(float)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â å°†ç³»åˆ—çš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºfloatÂ 
s.replace(1,'one')Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â 1Â ç”¨Â 'one'Â 
s.replace([1,3],['one','three'])Â Â Â Â Â Â Â Â Â Â Â Â #Â æ›¿æ¢æ‰€æœ‰ç­‰äºçš„å€¼Â æ›¿æ¢ä¸ºæ‰€æœ‰1Â 'one'Â ï¼Œå¹¶Â 3Â ç”¨Â 'three'Â df.rename(columns=lambdaÂ x:Â xÂ +Â 1)Â Â Â Â Â Â Â Â Â Â #Â åˆ—çš„é‡å‘½åÂ 
df.rename(columns={'old_name':Â 'new_Â name'})#Â é€‰æ‹©æ€§é‡å‘½åÂ 
df.set_index('column_one')Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â æ›´æ”¹ç´¢å¼•Â 
df.rename(index=lambdaÂ x:Â xÂ +Â 1)Â Â Â Â Â Â Â Â Â Â Â Â #Â å¤§è§„æ¨¡é‡å‘½åç´¢å¼•
```

#### ç­›é€‰ï¼Œæ’åºå’Œåˆ†ç»„ä¾æ®

```
df[df[col]Â &gt;Â 0.5]Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â åˆ—Â colÂ å¤§äºÂ 0.5Â df[(df[col]Â &gt;Â 0.5)Â &amp;Â (df[col]Â &lt;Â 0.7)]Â Â #Â å°äºÂ 0.7Â å¤§äº0.5çš„è¡ŒÂ 
df.sort_values(col1)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â æŒ‰col1å‡åºå¯¹å€¼è¿›è¡Œæ’åºÂ 
df.sort_values(col2,ascending=False)Â Â Â #Â æŒ‰col2Â é™åºå¯¹å€¼è¿›è¡ŒÂ æ’åºÂ 
df.sort_values([col1,col2],ascending=[True,False])Â #æŒ‰Â col1Â å‡åºæ’åºï¼Œç„¶åÂ col2Â æŒ‰é™åºæ’åºÂ 
df.groupby(col)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #ä»ä¸€ä¸ªæ è¿”å›GROUPBYå¯¹è±¡Â 
df.groupby([col1,col2])Â #Â è¿”å›æ¥è‡ªå¤šä¸ªåˆ—çš„groupbyå¯¹è±¡Â 
df.groupby(col1)[col2]Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â è¿”å›ä¸­çš„å€¼çš„å¹³å‡å€¼Â col2ï¼ŒæŒ‰ä¸­çš„å€¼åˆ†ç»„Â col1Â ï¼ˆå¹³å‡å€¼å¯ä»¥ç”¨ç»Ÿè®¡æ¨¡å—ä¸­çš„å‡ ä¹æ‰€æœ‰å‡½æ•°æ›¿æ¢Â ï¼‰Â 
df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean)Â #Â åˆ›å»ºä¸€ä¸ªæ•°æ®é€è§†è¡¨ç»„é€šè¿‡Â col1Â ï¼Œå¹¶è®¡ç®—å¹³å‡å€¼çš„Â col2Â å’ŒÂ col3Â 
df.groupby(col1).agg(np.mean)Â Â Â Â Â Â Â Â Â Â #Â åœ¨æ‰€æœ‰åˆ—ä¸­æ‰¾åˆ°æ¯ä¸ªå”¯ä¸€col1Â ç»„çš„å¹³å‡å€¼Â 
df.apply(np.mean)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #np.mean()Â åœ¨æ¯åˆ—ä¸Šåº”ç”¨è¯¥å‡½æ•°Â 
df.apply(np.max,axis=1)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â np.max()Â åœ¨æ¯è¡Œä¸Šåº”ç”¨åŠŸèƒ½
```

#### æ•°æ®åˆå¹¶

```
df1.append(df2)Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â #Â å°†df2æ·»åŠ Â df1çš„æœ«å°¾Â ï¼ˆå„åˆ—åº”ç›¸åŒï¼‰Â 
pd.concat([df1,Â df2],axis=1)Â Â Â Â Â Â #Â å°†Â df1çš„åˆ—æ·»åŠ åˆ°df2çš„æœ«å°¾Â ï¼ˆè¡Œåº”ç›¸åŒï¼‰Â 
df1.join(df2,on=col1,how='inner')Â # SQLæ ·å¼å°†åˆ— df1 ä¸ df2 è¡Œæ‰€åœ¨çš„åˆ—col å…·æœ‰ç›¸åŒå€¼çš„åˆ—è¿æ¥èµ·æ¥ã€‚'how'å¯ä»¥æ˜¯ä¸€ä¸ªÂ 'left'ï¼ŒÂ 'right'ï¼ŒÂ 'outer'ï¼ŒÂ 'inner'
```

#### æ•°æ®ç»Ÿè®¡

```
df.describe()Â Â Â Â #Â æ•°å€¼åˆ—çš„æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯Â 
df.mean()Â Â Â Â Â Â Â Â #Â è¿”å›å‡å€¼çš„æ‰€æœ‰åˆ—Â 
df.corr()Â Â Â Â Â Â Â Â #Â è¿”å›DataFrameä¸­å„åˆ—ä¹‹é—´çš„ç›¸å…³æ€§Â 
df.count()Â Â Â Â Â Â Â #Â è¿”å›éç©ºå€¼çš„æ¯ä¸ªæ•°æ®å¸§åˆ—ä¸­çš„æ•°å­—Â 
df.max()Â Â Â Â Â Â Â Â Â #Â è¿”å›æ¯åˆ—ä¸­çš„æœ€é«˜å€¼Â 
df.min()Â Â Â Â Â Â Â Â Â #Â è¿”å›æ¯ä¸€åˆ—ä¸­çš„æœ€å°å€¼Â 
df.median()Â Â Â Â Â Â #Â è¿”å›æ¯åˆ—çš„ä¸­ä½æ•°Â 
df.std()Â Â Â Â Â Â Â Â Â #Â è¿”å›æ¯åˆ—çš„æ ‡å‡†åå·®
```

### 16ä¸ªå‡½æ•°ï¼Œç”¨äºæ•°æ®æ¸…æ´—

```
#Â å¯¼å…¥æ•°æ®é›†
importÂ pandasÂ asÂ pd

dfÂ ={'å§“å':['Â é»„åŒå­¦','é»„è‡³å°Š','é»„è€é‚ªÂ ','é™ˆå¤§ç¾','å­™å°šé¦™'],
Â Â Â Â Â 'è‹±æ–‡å':['HuangÂ tong_xue','huangÂ zhi_zun','HuangÂ Lao_xie','ChenÂ Da_mei','sunÂ shang_xiang'],
Â Â Â Â Â 'æ€§åˆ«':['ç”·','women','men','å¥³','ç”·'],
Â Â Â Â Â 'èº«ä»½è¯':['463895200003128433','429475199912122345','420934199110102311','431085200005230122','420953199509082345'],
Â Â Â Â Â 'èº«é«˜':['mid:175_good','low:165_bad','low:159_bad','high:180_verygood','low:172_bad'],
Â Â Â Â Â 'å®¶åº­ä½å€':['æ¹–åŒ—å¹¿æ°´','æ²³å—ä¿¡é˜³','å¹¿è¥¿æ¡‚æ—','æ¹–åŒ—å­æ„Ÿ','å¹¿ä¸œå¹¿å·'],
Â Â Â Â Â 'ç”µè¯å·ç ':['13434813546','19748672895','16728613064','14561586431','19384683910'],
Â Â Â Â Â 'æ”¶å…¥':['1.1ä¸‡','8.5åƒ','0.9ä¸‡','6.5åƒ','2.0ä¸‡']}
dfÂ =Â pd.DataFrame(df)
df
```

<img src="https://img-blog.csdnimg.cn/img_convert/92581f83100aa94d8de7985d8b6bd4df.png" alt="92581f83100aa94d8de7985d8b6bd4df.png">

#### 1.catå‡½æ•°

ç”¨äºå­—ç¬¦ä¸²çš„æ‹¼æ¥

```
df["å§“å"].str.cat(df["å®¶åº­ä½å€"],sep='-'*3)
```

<img src="https://img-blog.csdnimg.cn/img_convert/17c4d39dfd6068abb730e1bb5270d378.png" alt="17c4d39dfd6068abb730e1bb5270d378.png">

#### 2.contains

åˆ¤æ–­æŸä¸ªå­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ç»™å®šå­—ç¬¦

```
df["å®¶åº­ä½å€"].str.contains("å¹¿")
```

<img src="https://img-blog.csdnimg.cn/img_convert/514a629578b19529bc51c1dcb1178568.png" alt="514a629578b19529bc51c1dcb1178568.png">

#### 3.startswith/endswith

åˆ¤æ–­æŸä¸ªå­—ç¬¦ä¸²æ˜¯å¦ä»¥â€¦å¼€å¤´/ç»“å°¾

```
#Â ç¬¬ä¸€ä¸ªè¡Œçš„â€œÂ é»„ä¼Ÿâ€æ˜¯ä»¥ç©ºæ ¼å¼€å¤´çš„
df["å§“å"].str.startswith("é»„")Â 
df["è‹±æ–‡å"].str.endswith("e")
```

#### 4.count

è®¡ç®—ç»™å®šå­—ç¬¦åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°

```
df["ç”µè¯å·ç "].str.count("3")
```

<img src="https://img-blog.csdnimg.cn/img_convert/9bc806ada2e5d5aba85f74e9fe460d01.png" alt="9bc806ada2e5d5aba85f74e9fe460d01.png">

#### 5.get

è·å–æŒ‡å®šä½ç½®çš„å­—ç¬¦ä¸²

```
df["å§“å"].str.get(-1)
df["èº«é«˜"].str.split(":")df["èº«é«˜"].str.split(":").str.get(0)
```

<img src="https://img-blog.csdnimg.cn/img_convert/59a5890d9017ab7c8117c6ba1c1f8576.png" alt="59a5890d9017ab7c8117c6ba1c1f8576.png">

#### 6.len

è®¡ç®—å­—ç¬¦ä¸²é•¿åº¦

```
df["æ€§åˆ«"].str.len()
```

<img src="https://img-blog.csdnimg.cn/img_convert/5be3091b0340b636248629bad5a8815b.png" alt="5be3091b0340b636248629bad5a8815b.png">

#### 7.upper/lower

è‹±æ–‡å¤§å°å†™è½¬æ¢

```
df["è‹±æ–‡å"].str.upper()
df["è‹±æ–‡å"].str.lower()
```

<img src="https://img-blog.csdnimg.cn/img_convert/a447cddc97609e3dc0f3ad90122f6826.png" alt="a447cddc97609e3dc0f3ad90122f6826.png">

#### 8.pad+sideå‚æ•°/center

åœ¨å­—ç¬¦ä¸²çš„å·¦è¾¹ã€å³è¾¹æˆ–å·¦å³ä¸¤è¾¹æ·»åŠ ç»™å®šå­—ç¬¦

```
df["å®¶åº­ä½å€"].str.pad(10,fillchar="*")Â Â Â Â Â Â #Â ç›¸å½“äºljust()
df["å®¶åº­ä½å€"].str.pad(10,side="right",fillchar="*")Â Â Â Â #Â ç›¸å½“äºrjust()
df["å®¶åº­ä½å€"].str.center(10,fillchar="*")
```

<img src="https://img-blog.csdnimg.cn/img_convert/adbdb80748b0c53f1017b1caf9db236a.png" alt="adbdb80748b0c53f1017b1caf9db236a.png">

#### 9.repeat

é‡å¤å­—ç¬¦ä¸²å‡ æ¬¡

```
df["æ€§åˆ«"].str.repeat(3)
```

<img src="https://img-blog.csdnimg.cn/img_convert/42f5e1f3d4e97d326fa28009e4138945.png" alt="42f5e1f3d4e97d326fa28009e4138945.png">

#### 10.slice_replace

ä½¿ç”¨ç»™å®šçš„å­—ç¬¦ä¸²ï¼Œæ›¿æ¢æŒ‡å®šçš„ä½ç½®çš„å­—ç¬¦

```
df["ç”µè¯å·ç "].str.slice_replace(4,8,"*"*4)
```

<img src="https://img-blog.csdnimg.cn/img_convert/3d46f8ec9861289d8f93978b0b496eed.png" alt="3d46f8ec9861289d8f93978b0b496eed.png">

#### 11.replace

å°†æŒ‡å®šä½ç½®çš„å­—ç¬¦ï¼Œæ›¿æ¢ä¸ºç»™å®šçš„å­—ç¬¦ä¸²

```
df["èº«é«˜"].str.replace(":","-")
```

<img src="https://img-blog.csdnimg.cn/img_convert/64c8bbeaaf18d0b1ad29a63aa701ac0b.png" alt="64c8bbeaaf18d0b1ad29a63aa701ac0b.png">

#### 12.replace

å°†æŒ‡å®šä½ç½®çš„å­—ç¬¦ï¼Œæ›¿æ¢ä¸ºç»™å®šçš„å­—ç¬¦ä¸²(æ¥å—æ­£åˆ™è¡¨è¾¾å¼)
- replaceä¸­ä¼ å…¥æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ‰å«å¥½ç”¨ï¼›- å…ˆä¸è¦ç®¡ä¸‹é¢è¿™ä¸ªæ¡ˆä¾‹æœ‰æ²¡æœ‰ç”¨ï¼Œä½ åªéœ€è¦çŸ¥é“ï¼Œä½¿ç”¨æ­£åˆ™åšæ•°æ®æ¸…æ´—å¤šå¥½ç”¨ï¼›
```
df["æ”¶å…¥"].str.replace("\d+\.\d+","æ­£åˆ™")
```

<img src="https://img-blog.csdnimg.cn/img_convert/0b07661047a16b39671aad590cafb768.png" alt="0b07661047a16b39671aad590cafb768.png">

#### 13.splitæ–¹æ³•+expandå‚æ•°

æ­é…joinæ–¹æ³•åŠŸèƒ½å¾ˆå¼ºå¤§

```
#Â æ™®é€šç”¨æ³•
df["èº«é«˜"].str.split(":")
#Â splitæ–¹æ³•ï¼Œæ­é…expandå‚æ•°
df[["èº«é«˜æè¿°","finalèº«é«˜"]]Â =Â df["èº«é«˜"].str.split(":",expand=True)
df
#Â splitæ–¹æ³•æ­é…joinæ–¹æ³•
df["èº«é«˜"].str.split(":").str.join("?"*5)
```

<img src="https://img-blog.csdnimg.cn/img_convert/dcc6304a9f42f07a05dbf5bc66b6258b.png" alt="dcc6304a9f42f07a05dbf5bc66b6258b.png">

#### 14.strip/rstrip/lstrip

å»é™¤ç©ºç™½ç¬¦ã€æ¢è¡Œç¬¦

```
df["å§“å"].str.len()
df["å§“å"]Â =Â df["å§“å"].str.strip()
df["å§“å"].str.len()
```

<img src="https://img-blog.csdnimg.cn/img_convert/eb638af9420afc6f0326624f12c582cb.png" alt="eb638af9420afc6f0326624f12c582cb.png">

#### 15.findall

åˆ©ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œå»å­—ç¬¦ä¸²ä¸­åŒ¹é…ï¼Œè¿”å›æŸ¥æ‰¾ç»“æœçš„åˆ—è¡¨
- findallä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œåšæ•°æ®æ¸…æ´—ï¼ŒçœŸçš„å¾ˆé¦™ï¼
```
df["èº«é«˜"]
df["èº«é«˜"].str.findall("[a-zA-Z]+")
```

<img src="https://img-blog.csdnimg.cn/img_convert/069fb6257f6fdc967be8479189a08c6c.png" alt="069fb6257f6fdc967be8479189a08c6c.png">

#### 16.extract/extractall

æ¥å—æ­£åˆ™è¡¨è¾¾å¼ï¼ŒæŠ½å–åŒ¹é…çš„å­—ç¬¦ä¸²(ä¸€å®šè¦åŠ ä¸Šæ‹¬å·)

```
df["èº«é«˜"].str.extract("([a-zA-Z]+)")
#Â extractallæå–å¾—åˆ°å¤åˆç´¢å¼•
df["èº«é«˜"].str.extractall("([a-zA-Z]+)")
#Â extractæ­é…expandå‚æ•°
df["èº«é«˜"].str.extract("([a-zA-Z]+).*?([a-zA-Z]+)",expand=True)
```

<img src="https://img-blog.csdnimg.cn/img_convert/6f76a8e60f15d3b656938d2c251ff175.png" alt="6f76a8e60f15d3b656938d2c251ff175.png">

æ¥æºï¼šhttps://github.com/SeafyLiang/Python_study

æ¨èé˜…è¯»Â Â ç‚¹å‡»æ ‡é¢˜å¯è·³è½¬
- - - - - - - - - 